GLOB sdist-make: /code/modules/invenio-stats/setup.py
c1 inst-nodeps: /code/modules/invenio-stats/.tox/.tmp/package/1/invenio-stats-1.0.0a10.zip
c1 installed: alabaster==0.7.13,alembic==0.9.6,amqp==2.6.0,angular-gettext-babel==0.3,aniso8601==8.0.0,arrow==0.12.1,asn1crypto==0.23.0,atomicwrites==1.4.1,attrs==17.4.0,b2handle==1.1.2,Babel==2.5.1,bagit==1.7.0,beautifulsoup4==4.9.3,bibtexparser==1.0.1,billiard==3.6.3.0,binaryornot==0.4.4,bleach==3.1.0,blinker==1.4,boto3==1.7.84,botocore==1.10.84,cachelib==0.1,cachetools==4.2.4,cchardet==2.1.1,celery==4.4.4,certifi==2017.11.5,cffi==1.11.2,chardet==3.0.4,citeproc-py==0.5.1,citeproc-py-styles==0.1.2,click==6.7,cookiecutter==1.6.0,counter-robots==2018.6,coverage==6.2,cryptography==2.1.4,datacite==1.0.1,DateTime==4.9,decorator==4.1.2,defusedxml==0.5.0,dictdiffer==0.7.0,distlib==0.3.6,dnspython==2.2.1,docutils==0.18.1,dojson==1.3.2,elasticsearch==6.1.1,elasticsearch-dsl==6.4.0,elementpath==1.0.6,email-validator==1.0.5,entrypoints==0.2.3,feedgen==0.7.0,filelock==3.4.1,Flask==1.1.0,Flask-Admin==1.5.3,Flask-Alembic==2.0.1,Flask-Assets==0.12,Flask-BabelEx==0.9.4,Flask-Breadcrumbs==0.5.0,Flask-Caching==1.10.1,Flask-CeleryExt==0.3.4,Flask-Collect==1.2.2,Flask-Cors==3.0.3,Flask-DebugToolbar==0.13.1,Flask-IIIF==0.6.1,Flask-KVSession==0.6.2,Flask-Limiter==1.1.0,Flask-Login==0.4.1,Flask-Mail==0.9.1,flask-marshmallow==0.14.0,Flask-Menu==0.6.0,-e git+https://github.com/RCOSDP/flask-oauthlib.git@98eb36e1dfc66256fa7ea62237e9879acb906e9d#egg=Flask_OAuthlib,Flask-Plugins==1.6.1,Flask-Principal==0.4.0,Flask-RESTful==0.3.8,Flask-Security==3.0.0,flask-shell-ipython==0.4.1,Flask-Sitemap==0.4.0,Flask-SQLAlchemy==2.3.2,flask-talisman==0.4.1,Flask-WTF==0.14.3,-e git+https://github.com/RCOSDP/pyfpdf.git@f9b032148283d535cabc7789858081c80de36fef#egg=fpdf,frozendict==2.3.8,fs==0.5.4,ftfy==4.4.3,future==0.16.0,github3.py==1.1.0,html5lib==1.0.1,idna==2.6,iiif-prezi==0.3.0,imagesize==1.4.1,importlib-metadata==4.8.3,importlib-resources==5.4.0,infinity==1.4,intervals==0.8.0,invenio-access==1.1.0,-e git+https://github.com/RCOSDP/weko.git@84633f34226891a4a701dee9c8eec64294b0446c#egg=invenio_accounts&subdirectory=modules/invenio-accounts,invenio-admin==1.1.2,invenio-app==1.1.0,invenio-assets==1.0.0,invenio-base==1.0.2,invenio-cache==1.0.0,invenio-celery==1.1.3,-e git+https://github.com/RCOSDP/weko.git@84633f34226891a4a701dee9c8eec64294b0446c#egg=invenio_communities&subdirectory=modules/invenio-communities,invenio-config==1.0.0,invenio-csl-rest==1.0.0a1,-e git+https://github.com/RCOSDP/weko.git@84633f34226891a4a701dee9c8eec64294b0446c#egg=invenio_db&subdirectory=modules/invenio-db,-e git+https://github.com/RCOSDP/weko.git@84633f34226891a4a701dee9c8eec64294b0446c#egg=invenio_deposit&subdirectory=modules/invenio-deposit,-e git+https://github.com/RCOSDP/weko.git@84633f34226891a4a701dee9c8eec64294b0446c#egg=invenio_files_rest&subdirectory=modules/invenio-files-rest,invenio-formatter==1.0.0b3,invenio-i18n==1.0.0,-e git+https://github.com/RCOSDP/weko.git@84633f34226891a4a701dee9c8eec64294b0446c#egg=invenio_iiif&subdirectory=modules/invenio-iiif,-e git+https://github.com/RCOSDP/weko.git@84633f34226891a4a701dee9c8eec64294b0446c#egg=invenio_indexer&subdirectory=modules/invenio-indexer,invenio-jsonschemas==1.0.0,invenio-logging==1.0.0b3,-e git+https://github.com/RCOSDP/weko.git@84633f34226891a4a701dee9c8eec64294b0446c#egg=invenio_mail&subdirectory=modules/invenio-mail,invenio-marc21==1.0.0a8,-e git+https://github.com/RCOSDP/weko.git@84633f34226891a4a701dee9c8eec64294b0446c#egg=invenio_oaiharvester&subdirectory=modules/invenio-oaiharvester,-e git+https://github.com/RCOSDP/weko.git@84633f34226891a4a701dee9c8eec64294b0446c#egg=invenio_oaiserver&subdirectory=modules/invenio-oaiserver,-e git+https://github.com/RCOSDP/weko.git@84633f34226891a4a701dee9c8eec64294b0446c#egg=invenio_oauth2server&subdirectory=modules/invenio-oauth2server,invenio-oauthclient==1.0.0,invenio-pidrelations==1.0.0a4,invenio-pidstore==1.0.0,-e git+https://github.com/RCOSDP/weko.git@84633f34226891a4a701dee9c8eec64294b0446c#egg=invenio_previewer&subdirectory=modules/invenio-previewer,invenio-query-parser==0.6.0,-e git+https://github.com/RCOSDP/weko.git@84633f34226891a4a701dee9c8eec64294b0446c#egg=invenio_queues&subdirectory=modules/invenio-queues,-e git+https://github.com/RCOSDP/weko.git@84633f34226891a4a701dee9c8eec64294b0446c#egg=invenio_records&subdirectory=modules/invenio-records,invenio-records-files==1.0.0a10,-e git+https://github.com/RCOSDP/weko.git@84633f34226891a4a701dee9c8eec64294b0446c#egg=invenio_records_rest&subdirectory=modules/invenio-records-rest,invenio-records-ui==1.0.0,-e git+https://github.com/RCOSDP/weko.git@84633f34226891a4a701dee9c8eec64294b0446c#egg=invenio_resourcesyncclient&subdirectory=modules/invenio-resourcesyncclient,-e git+https://github.com/RCOSDP/weko.git@84633f34226891a4a701dee9c8eec64294b0446c#egg=invenio_resourcesyncserver&subdirectory=modules/invenio-resourcesyncserver,invenio-rest==1.1.2,-e git+https://github.com/RCOSDP/weko.git@84633f34226891a4a701dee9c8eec64294b0446c#egg=invenio_s3&subdirectory=modules/invenio-s3,-e git+https://github.com/RCOSDP/invenio-search.git@cff9744c5dc651893a9c51672c5b8da9adc21e16#egg=invenio_search,-e git+https://github.com/RCOSDP/invenio-search-ui.git@74bd3b2990ff27b39e01b6b31be9a0b5fda3dd0f#egg=invenio_search_ui,invenio-stats @ file:///code/modules/invenio-stats/.tox/.tmp/package/1/invenio-stats-1.0.0a10.zip,invenio-theme==1.0.0b4,ipaddress==1.0.19,ipython==6.2.1,ipython-genutils==0.2.0,itsdangerous==0.24,jedi==0.11.0,Jinja2==2.10.1,jinja2-cli==0.6.0,jinja2-time==0.2.0,jmespath==0.10.0,jsmin==2.2.2,jsonpatch==1.21,jsonpath-ng==1.5.2,jsonpointer==1.14,jsonref==0.1,jsonresolver==0.2.1,jsonschema==2.6.0,jupyter-client==5.2.2,jupyter-core==4.4.0,-e git+https://github.com/RCOSDP/kombu.git@f204fdf078d5e94393c86693f545e2d011f620f5#egg=kombu,limits==1.2.1,lxml==4.1.1,Mako==1.0.7,MarkupSafe==1.1.1,marshmallow==2.20.1,marshmallow-sqlalchemy==0.23.1,maxminddb==1.5.2,maxminddb-geolite2==2017.803,mistune==0.8.3,mock==5.0.2,more-itertools==8.10.0,msgpack==0.6.2,nbconvert==5.3.1,nbformat==4.4.0,netaddr==0.8.0,node-semver==0.1.1,numpy==1.16.1,oauthlib==2.1.0,ordereddict==1.1,packaging==21.3,pandocfilters==1.4.2,parso==0.1.0,passlib==1.7.1,pbr==5.11.1,pexpect==4.3.0,pickleshare==0.7.4,Pillow==5.4.1,platformdirs==2.4.0,pluggy==0.13.1,ply==3.11,poyo==0.4.1,prompt-toolkit==1.0.15,psycopg2==2.7.3.2,ptyprocess==0.5.2,py==1.11.0,pycparser==2.18,Pygments==2.2.0,PyJWT==1.5.3,PyLD==2.0.3,pyparsing==3.1.0,-e git+https://github.com/RCOSDP/PyPDF2.git@fefc684a3a74aff6f99e5dff24f9b4dd1c95169d#egg=PyPDF2,pyPEG2==2.15.2,pytest==4.2.0,pytest-cov==2.9.0,pytest-flask==0.15.1,pytest-invenio==1.2.1,python-dateutil==2.6.1,python-editor==1.0.3,python-geoip==1.2,pytz==2017.3,pyzmq==17.0.0,redis==2.10.6,requests==2.18.4,requests-oauthlib==1.1.0,resync==1.0.9,s3fs==0.1.6,s3transfer==0.1.13,selenium==3.141.0,Sickle==0.6.4,simplegeneric==0.8.1,simplejson==3.12.0,simplekv==0.11.2,six==1.16.0,snowballstemmer==2.2.0,soupsieve==2.3.2.post1,speaklater==1.3,Sphinx==1.8.4,sphinxcontrib-serializinghtml==1.1.5,sphinxcontrib-websupport==1.2.4,SQLAlchemy==1.2.19,SQLAlchemy-Continuum==1.3.6,SQLAlchemy-Utils==0.35.0,stevedore==3.5.2,sword3common==0.1.1,testpath==0.3.1,tika==2.6.0,toml==0.10.2,tornado==4.5.3,tox==3.28.0,traitlets==4.3.2,typing_extensions==4.1.1,ua-parser==0.7.3,uritemplate==4.1.1,uritools==2.1.0,urllib3==1.22,uWSGI==2.0.21,uwsgitop==0.11,validators==0.12.0,vine==1.3.0,virtualenv==20.17.1,virtualenv-clone==0.5.7,virtualenvwrapper==4.8.4,Wand==0.6.1,wcwidth==0.1.7,webargs==5.5.2,webassets==0.12.1,webencodings==0.5.1,-e git+https://github.com/RCOSDP/weko.git@84633f34226891a4a701dee9c8eec64294b0446c#egg=weko_accounts&subdirectory=modules/weko-accounts,-e git+https://github.com/RCOSDP/weko.git@84633f34226891a4a701dee9c8eec64294b0446c#egg=weko_admin&subdirectory=modules/weko-admin,-e git+https://github.com/RCOSDP/weko.git@84633f34226891a4a701dee9c8eec64294b0446c#egg=weko_authors&subdirectory=modules/weko-authors,-e git+https://github.com/RCOSDP/weko.git@84633f34226891a4a701dee9c8eec64294b0446c#egg=weko_bulkupdate&subdirectory=modules/weko-bulkupdate,-e git+https://github.com/RCOSDP/weko.git@84633f34226891a4a701dee9c8eec64294b0446c#egg=weko_deposit&subdirectory=modules/weko-deposit,-e git+https://github.com/RCOSDP/weko.git@84633f34226891a4a701dee9c8eec64294b0446c#egg=weko_gridlayout&subdirectory=modules/weko-gridlayout,-e git+https://github.com/RCOSDP/weko.git@84633f34226891a4a701dee9c8eec64294b0446c#egg=weko_groups&subdirectory=modules/weko-groups,-e git+https://github.com/RCOSDP/weko.git@84633f34226891a4a701dee9c8eec64294b0446c#egg=weko_handle&subdirectory=modules/weko-handle,-e git+https://github.com/RCOSDP/weko.git@84633f34226891a4a701dee9c8eec64294b0446c#egg=weko_index_tree&subdirectory=modules/weko-index-tree,-e git+https://github.com/RCOSDP/weko.git@84633f34226891a4a701dee9c8eec64294b0446c#egg=weko_indextree_journal&subdirectory=modules/weko-indextree-journal,-e git+https://github.com/RCOSDP/weko.git@84633f34226891a4a701dee9c8eec64294b0446c#egg=weko_items_autofill&subdirectory=modules/weko-items-autofill,-e git+https://github.com/RCOSDP/weko.git@84633f34226891a4a701dee9c8eec64294b0446c#egg=weko_items_ui&subdirectory=modules/weko-items-ui,-e git+https://github.com/RCOSDP/weko.git@84633f34226891a4a701dee9c8eec64294b0446c#egg=weko_itemtypes_ui&subdirectory=modules/weko-itemtypes-ui,-e git+https://github.com/RCOSDP/weko.git@84633f34226891a4a701dee9c8eec64294b0446c#egg=weko_logging&subdirectory=modules/weko-logging,-e git+https://github.com/RCOSDP/weko.git@84633f34226891a4a701dee9c8eec64294b0446c#egg=weko_records&subdirectory=modules/weko-records,-e git+https://github.com/RCOSDP/weko.git@84633f34226891a4a701dee9c8eec64294b0446c#egg=weko_records_ui&subdirectory=modules/weko-records-ui,-e git+https://github.com/RCOSDP/weko.git@84633f34226891a4a701dee9c8eec64294b0446c#egg=weko_redis&subdirectory=modules/weko-redis,-e git+https://github.com/RCOSDP/weko.git@84633f34226891a4a701dee9c8eec64294b0446c#egg=weko_schema_ui&subdirectory=modules/weko-schema-ui,-e git+https://github.com/RCOSDP/weko.git@84633f34226891a4a701dee9c8eec64294b0446c#egg=weko_search_ui&subdirectory=modules/weko-search-ui,-e git+https://github.com/RCOSDP/weko.git@84633f34226891a4a701dee9c8eec64294b0446c#egg=weko_sitemap&subdirectory=modules/weko-sitemap,-e git+https://github.com/RCOSDP/weko.git@84633f34226891a4a701dee9c8eec64294b0446c#egg=weko_swordserver&subdirectory=modules/weko-swordserver,-e git+https://github.com/RCOSDP/weko.git@84633f34226891a4a701dee9c8eec64294b0446c#egg=weko_theme&subdirectory=modules/weko-theme,-e git+https://github.com/RCOSDP/weko.git@84633f34226891a4a701dee9c8eec64294b0446c#egg=weko_user_profiles&subdirectory=modules/weko-user-profiles,-e git+https://github.com/RCOSDP/weko.git@84633f34226891a4a701dee9c8eec64294b0446c#egg=weko_workflow&subdirectory=modules/weko-workflow,Werkzeug==0.15.2,whichcraft==0.4.1,WTForms==2.1,WTForms-Alchemy==0.16.5,WTForms-Components==0.10.3,xmlschema==0.9.30,xmltodict==0.12.0,zipp==3.6.0,zope.interface==5.5.2
c1 run-test-pre: PYTHONHASHSEED='410629511'
c1 run-test: commands[0] | pytest --cov=invenio_stats tests -v -vv --cov-branch --cov-report=term --cov-report=xml --cov-report=html --cov-config=tox.ini --basetemp=/code/modules/invenio-stats/.tox/c1/tmp
============================= test session starts ==============================
platform linux -- Python 3.6.15, pytest-4.2.0, py-1.11.0, pluggy-0.13.1 -- /code/modules/invenio-stats/.tox/c1/bin/python
cachedir: .tox/c1/.pytest_cache
rootdir: /code/modules/invenio-stats, inifile:
plugins: celery-4.4.4, flask-0.15.1, cov-2.9.0, invenio-1.2.1
collecting ... collected 130 items

tests/test_aggregations.py::test_BookmarkAPI PASSED                      [  0%]
tests/test_aggregations.py::test_wrong_intervals PASSED                  [  1%]
tests/test_aggregations.py::test_StatAggregator PASSED                   [  2%]
tests/test_cli.py::test_events_process FAILED                            [  3%]
tests/test_cli.py::test_events_delete_restore PASSED                     [  3%]
tests/test_cli.py::test_aggregations_process[indexed_file_download_events0] ERROR [  4%]
tests/test_cli.py::test_aggregations_delete[aggregated_file_download_events0] ERROR [  5%]
tests/test_cli.py::test_aggregations_list_bookmarks[aggregated_file_download_events0] ERROR [  6%]
tests/test_cli.py::test_aggregations_deleteindex_restore PASSED          [  6%]
tests/test_cli.py::test_partition_create PASSED                          [  7%]
tests/test_event_builders.py::test_celery_task_event_builder PASSED      [  8%]
tests/test_event_builders.py::test_file_download_event_builder PASSED    [  9%]
tests/test_event_builders.py::test_build_celery_task_unique_id PASSED    [ 10%]
tests/test_event_builders.py::test_copy_record_index_list PASSED         [ 10%]
tests/test_event_builders.py::test_copy_user_group_list PASSED           [ 11%]
tests/test_event_builders.py::test_copy_search_keyword PASSED            [ 12%]
tests/test_event_builders.py::test_copy_search_type PASSED               [ 13%]
tests/test_event_builders.py::test_record_view_event_builder PASSED      [ 13%]
tests/test_event_builders.py::test_top_view_event_builder PASSED         [ 14%]
tests/test_event_builders.py::test_build_top_unique_id PASSED            [ 15%]
tests/test_event_builders.py::test_build_item_create_unique_id PASSED    [ 16%]
tests/test_event_builders.py::test_resolve_address PASSED                [ 16%]
tests/test_event_builders.py::test_search_event_builder PASSED           [ 17%]
tests/test_event_builders.py::test_build_search_unique_id PASSED         [ 18%]
tests/test_event_builders.py::test_build_search_detail_condition PASSED  [ 19%]
tests/test_event_builders.py::test_item_create_event_builder PASSED      [ 20%]
tests/test_events.py::test_event_queues_declare SKIPPED                  [ 20%]
tests/test_events.py::test_publish_and_consume_events SKIPPED            [ 21%]
tests/test_invenio_stats.py::test_version PASSED                         [ 22%]
tests/test_invenio_stats.py::test_init PASSED                            [ 23%]
tests/test_models.py::test_StatsEvents PASSED                            [ 23%]
tests/test_models.py::test_StatsAggregation PASSED                       [ 24%]
tests/test_models.py::test_StatsBookmark PASSED                          [ 25%]
tests/test_models.py::test_get_stats_events_partition_tables PASSED      [ 26%]
tests/test_models.py::test_make_stats_events_partition_table PASSED      [ 26%]
tests/test_processors.py::test_anonymize_user[131.169.180.47-None-None-None-timestamp0-DE-1850abef504ce64cb6b38fa60fe8f90aede1d2d2e9013735554af946-1850abef504ce64cb6b38fa60fe8f90aede1d2d2e9013735554af946] PASSED [ 27%]
tests/test_processors.py::test_anonymize_user[188.184.37.205-100-None-None-timestamp1-CH-eaf6a44a598ea63c659e6e46722e2d11d0d7487694ec504ade273b9d-c6b85f117cd0636a07f1cf250a30d86714ec45e55a1110441d1a9e2b] PASSED [ 28%]
tests/test_processors.py::test_anonymize_user[23.22.39.120-100-foo-bar-timestamp2-US-eaf6a44a598ea63c659e6e46722e2d11d0d7487694ec504ade273b9d-c6b85f117cd0636a07f1cf250a30d86714ec45e55a1110441d1a9e2b] PASSED [ 29%]
tests/test_processors.py::test_anonymize_user[23.22.39.120-100-None-None-timestamp3-US-eaf6a44a598ea63c659e6e46722e2d11d0d7487694ec504ade273b9d-77536991d991e6e8251999fc6a8d78ec1be42847da3c8774221a03a0] PASSED [ 30%]
tests/test_processors.py::test_anonymize_user[23.22.39.120-100-None-None-timestamp4-US-eaf6a44a598ea63c659e6e46722e2d11d0d7487694ec504ade273b9d-77536991d991e6e8251999fc6a8d78ec1be42847da3c8774221a03a0] PASSED [ 30%]
tests/test_processors.py::test_anonymize_user[131.169.180.47-None-foo-None-timestamp5-DE-a78cc092c88fb4d060a873217f2cd466c2776f672a99ee06317c2858-ca28702a6ece34d18c6f6498ef79d77492a6bd653ac886beb5018880] PASSED [ 31%]
tests/test_processors.py::test_anonymize_user[131.169.180.47-None-foo-bar-timestamp6-DE-a78cc092c88fb4d060a873217f2cd466c2776f672a99ee06317c2858-ca28702a6ece34d18c6f6498ef79d77492a6bd653ac886beb5018880] PASSED [ 32%]
tests/test_processors.py::test_anonymize_user[131.169.180.47-None-foo-bar-timestamp7-DE-a78cc092c88fb4d060a873217f2cd466c2776f672a99ee06317c2858-ceb752c8b51c8c4a9c18a9d4404e9fb570fbf83195631ab3efb46b31] PASSED [ 33%]
tests/test_processors.py::test_anonymize_user[188.184.37.205-None-None-bar-timestamp8-CH-e9c48686d21c21a9ee5b9eba58b1d86c9460272809b6de71649f6ce7-e9c48686d21c21a9ee5b9eba58b1d86c9460272809b6de71649f6ce7] PASSED [ 33%]
tests/test_processors.py::test_anonymize_user[131.169.180.47-None-None-bar-timestamp9-DE-602e9bc738b422d5a19283e20fc31ec540a12d42b04ad7073d943fb2-602e9bc738b422d5a19283e20fc31ec540a12d42b04ad7073d943fb2] PASSED [ 34%]
tests/test_processors.py::test_anonymize_user[131.169.180.47-None-None-bar-timestamp10-DE-4b30c060f422f304b073759553d4161a14784e0ddcf57284f55d7cae-4b30c060f422f304b073759553d4161a14784e0ddcf57284f55d7cae] PASSED [ 35%]
tests/test_processors.py::test_anonymize_user[0.0.0.0-None-None-None-timestamp11-None-1850abef504ce64cb6b38fa60fe8f90aede1d2d2e9013735554af946-1850abef504ce64cb6b38fa60fe8f90aede1d2d2e9013735554af946] PASSED [ 36%]
tests/test_processors.py::test_anonymiation_salt PASSED                  [ 36%]
tests/test_processors.py::test_events_indexer_preprocessors PASSED       [ 37%]
tests/test_processors.py::test_events_indexer_id_windowing PASSED        [ 38%]
tests/test_processors.py::test_double_clicks FAILED                      [ 39%]
tests/test_processors.py::test_failing_processors SKIPPED                [ 40%]
tests/test_queries.py::test_query PASSED                                 [ 40%]
tests/test_queries.py::test_date_histogram_query FAILED                  [ 41%]
tests/test_queries.py::test_terms_query[mock_execute0-1-tests/data/ESTermsQuery_result01.json-aggregated_file_download_events0] ERROR [ 42%]
tests/test_queries.py::test_terms_query[mock_execute1-1-tests/data/ESTermsQuery_result02.json-aggregated_file_download_events0] ERROR [ 43%]
tests/test_queries.py::test_terms_query[mock_execute2-16-tests/data/ESTermsQuery_result03.json-aggregated_file_download_events0] ERROR [ 43%]
tests/test_queries.py::test_terms_query2 FAILED                          [ 44%]
tests/test_queries.py::test_weko_file_stats_query FAILED                 [ 45%]
tests/test_queries.py::test_weko_terms_query FAILED                      [ 46%]
tests/test_queries.py::test_ESWekoFileRankingQuery FAILED                [ 46%]
tests/test_receivers.py::test_register_receivers SKIPPED                 [ 47%]
tests/test_receivers.py::test_failing_receiver SKIPPED                   [ 48%]
tests/test_tasks.py::test_process_events FAILED                          [ 49%]
tests/test_utils.py::test_get_anonymization_salt PASSED                  [ 50%]
tests/test_utils.py::test_get_geoip PASSED                               [ 50%]
tests/test_utils.py::test_get_user PASSED                                [ 51%]
tests/test_utils.py::test_obj_or_import_string PASSED                    [ 52%]
tests/test_utils.py::test_load_or_import_from_config PASSED              [ 53%]
tests/test_utils.py::test_default_permission_factory PASSED              [ 53%]
tests/test_utils.py::test_get_aggregations FAILED                        [ 54%]
tests/test_utils.py::test_get_start_end_date PASSED                      [ 55%]
tests/test_utils.py::test_agg_bucket_sort PASSED                         [ 56%]
tests/test_utils.py::test_parse_bucket_response PASSED                   [ 56%]
tests/test_utils.py::test_get_doctype PASSED                             [ 57%]
tests/test_utils.py::test_is_valid_access PASSED                         [ 58%]
tests/test_utils.py::test_query_file_reports_helper[aggregated_file_download_events0] ERROR [ 59%]
tests/test_utils.py::test_query_file_reports_helper_error PASSED         [ 60%]
tests/test_utils.py::test_query_search_report_helper PASSED              [ 60%]
tests/test_utils.py::test_query_search_report_helper_error PASSED        [ 61%]
tests/test_utils.py::test_query_common_reports_helper PASSED             [ 62%]
tests/test_utils.py::test_query_common_reports_helper_error PASSED       [ 63%]
tests/test_utils.py::test_query_record_view_per_index_report_helper PASSED [ 63%]
tests/test_utils.py::test_query_record_view_per_index_report_helper_error PASSED [ 64%]
tests/test_utils.py::test_query_record_view_report_helper FAILED         [ 65%]
tests/test_utils.py::test_query_record_view_report_helper_error PASSED   [ 66%]
tests/test_utils.py::test_query_item_reg_report_helper FAILED            [ 66%]
tests/test_utils.py::test_query_item_reg_report_helper_error PASSED      [ 67%]
tests/test_utils.py::test_query_ranking_helper PASSED                    [ 68%]
tests/test_utils.py::test_query_ranking_helper_error PASSED              [ 69%]
tests/test_utils.py::test_StatsCliUtil PASSED                            [ 70%]
tests/test_views.py::test_stats_query_resource_guest PASSED              [ 70%]
tests/test_views.py::test_stats_query_resource_com PASSED                [ 71%]
tests/test_views.py::test_stats_query_resource_admin PASSED              [ 72%]
tests/test_views.py::test_stats_query_resource_error PASSED              [ 73%]
tests/test_views.py::test_query_record_view_count PASSED                 [ 73%]
tests/test_views.py::test_query_record_view_count_error PASSED           [ 74%]
tests/test_views.py::test_query_file_stats_count PASSED                  [ 75%]
tests/test_views.py::test_query_item_reg_report[0-403] PASSED            [ 76%]
tests/test_views.py::test_query_item_reg_report[1-200] PASSED            [ 76%]
tests/test_views.py::test_query_item_reg_report[2-200] PASSED            [ 77%]
tests/test_views.py::test_query_item_reg_report[3-403] PASSED            [ 78%]
tests/test_views.py::test_query_item_reg_report[4-403] PASSED            [ 79%]
tests/test_views.py::test_query_record_view_report[0-403] PASSED         [ 80%]
tests/test_views.py::test_query_record_view_report[1-200] PASSED         [ 80%]
tests/test_views.py::test_query_record_view_report[2-200] PASSED         [ 81%]
tests/test_views.py::test_query_record_view_report[3-403] PASSED         [ 82%]
tests/test_views.py::test_query_record_view_report[4-403] PASSED         [ 83%]
tests/test_views.py::test_query_record_view_per_index_report[0-403] PASSED [ 83%]
tests/test_views.py::test_query_record_view_per_index_report[1-200] PASSED [ 84%]
tests/test_views.py::test_query_record_view_per_index_report[2-200] PASSED [ 85%]
tests/test_views.py::test_query_record_view_per_index_report[3-403] PASSED [ 86%]
tests/test_views.py::test_query_record_view_per_index_report[4-403] PASSED [ 86%]
tests/test_views.py::test_query_file_reports[0-403] PASSED               [ 87%]
tests/test_views.py::test_query_file_reports[1-200] PASSED               [ 88%]
tests/test_views.py::test_query_file_reports[2-200] PASSED               [ 89%]
tests/test_views.py::test_query_file_reports[3-403] PASSED               [ 90%]
tests/test_views.py::test_query_file_reports[4-403] PASSED               [ 90%]
tests/test_views.py::test_query_common_reports PASSED                    [ 91%]
tests/test_views.py::test_query_celery_task_report[0-403] PASSED         [ 92%]
tests/test_views.py::test_query_celery_task_report[1-200] PASSED         [ 93%]
tests/test_views.py::test_query_celery_task_report[2-200] PASSED         [ 93%]
tests/test_views.py::test_query_celery_task_report[3-403] PASSED         [ 94%]
tests/test_views.py::test_query_celery_task_report[4-403] PASSED         [ 95%]
tests/test_views.py::test_query_search_report[0-403] PASSED              [ 96%]
tests/test_views.py::test_query_search_report[1-200] PASSED              [ 96%]
tests/test_views.py::test_query_search_report[2-200] PASSED              [ 97%]
tests/test_views.py::test_query_search_report[3-403] PASSED              [ 98%]
tests/test_views.py::test_query_search_report[4-403] PASSED              [ 99%]
tests/test_views.py::test_dbsession_clean PASSED                         [100%]

==================================== ERRORS ====================================
__ ERROR at setup of test_aggregations_process[indexed_file_download_events0] __

app = <Flask 'testapp'>
es = <Elasticsearch([{'host': 'elasticsearch', 'port': 9200}])>
mock_user_ctx = None
request = <SubRequest 'indexed_file_download_events' for <Function test_aggregations_process[indexed_file_download_events0]>>

    @pytest.yield_fixture()
    def indexed_file_download_events(app, es, mock_user_ctx, request):
        """Parametrized pre indexed sample events."""
>       generate_file_events(app=app, event_type="file-download", **request.param)

tests/conftest.py:900: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
tests/conftest.py:894: in generate_file_events
    process_events([event_type])
.tox/c1/lib/python3.6/site-packages/celery/local.py:191: in __call__
    return self._get_current_object()(*a, **kw)
.tox/c1/lib/python3.6/site-packages/celery/app/task.py:392: in __call__
    return self.run(*args, **kwargs)
invenio_stats/tasks.py:27: in process_events
    results.append((e, processor.run()))
invenio_stats/processors.py:243: in run
    chunk_size=50
.tox/c1/lib/python3.6/site-packages/elasticsearch/helpers/__init__.py:257: in bulk
    for ok, item in streaming_bulk(client, actions, **kwargs):
.tox/c1/lib/python3.6/site-packages/elasticsearch/helpers/__init__.py:180: in streaming_bulk
    client.transport.serializer):
.tox/c1/lib/python3.6/site-packages/elasticsearch/helpers/__init__.py:58: in _chunk_actions
    for action, data in actions:
invenio_stats/processors.py:192: in actionsiter
    for msg in self.queue.consume():
../invenio-queues/invenio_queues/queue.py:107: in consume
    with self.create_consumer() as consumer:
/usr/local/lib/python3.6/contextlib.py:81: in __enter__
    return next(self.gen)
../invenio-queues/invenio_queues/queue.py:96: in create_consumer
    yield self.consumer(conn)
../invenio-queues/invenio_queues/queue.py:83: in consumer
    no_ack=self.no_ack,
.tox/c1/src/kombu/kombu/compat.py:119: in __init__
    super(Consumer, self).__init__(self.backend, queue, **kwargs)
.tox/c1/src/kombu/kombu/messaging.py:386: in __init__
    self.revive(self.channel)
.tox/c1/src/kombu/kombu/compat.py:123: in revive
    super(Consumer, self).revive(channel)
.tox/c1/src/kombu/kombu/messaging.py:408: in revive
    self.declare()
.tox/c1/src/kombu/kombu/messaging.py:421: in declare
    queue.declare()
.tox/c1/src/kombu/kombu/entity.py:611: in declare
    self._create_queue(nowait=nowait, channel=channel)
.tox/c1/src/kombu/kombu/entity.py:620: in _create_queue
    self.queue_declare(nowait=nowait, passive=False, channel=channel)
.tox/c1/src/kombu/kombu/entity.py:655: in queue_declare
    nowait=nowait,
.tox/c1/lib/python3.6/site-packages/amqp/channel.py:1149: in queue_declare
    spec.Queue.DeclareOk, returns_tuple=True,
.tox/c1/lib/python3.6/site-packages/amqp/abstract_channel.py:88: in wait
    self.connection.drain_events(timeout=timeout)
.tox/c1/lib/python3.6/site-packages/amqp/connection.py:508: in drain_events
    while not self.blocking_read(timeout):
.tox/c1/lib/python3.6/site-packages/amqp/connection.py:514: in blocking_read
    return self.on_inbound_frame(frame)
.tox/c1/lib/python3.6/site-packages/amqp/method_framing.py:55: in on_frame
    callback(channel, method_sig, buf, None)
.tox/c1/lib/python3.6/site-packages/amqp/connection.py:521: in on_inbound_method
    method_sig, payload, content,
.tox/c1/lib/python3.6/site-packages/amqp/abstract_channel.py:145: in dispatch_method
    listener(*args)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <kombu.transport.pyamqp.Channel object at 0x7effe51fab70>
reply_code = 406
reply_text = "PRECONDITION_FAILED - inequivalent arg 'x-queue-type' for queue 'stats-file-download' in vhost '/': received the value 'quorum' of type 'longstr' but current is none"
class_id = 50, method_id = 10

    def _on_close(self, reply_code, reply_text, class_id, method_id):
        """Request a channel close.
    
        This method indicates that the sender wants to close the
        channel. This may be due to internal conditions (e.g. a forced
        shut-down) or due to an error handling a specific method, i.e.
        an exception.  When a close is due to an exception, the sender
        provides the class and method id of the method which caused
        the exception.
    
        RULE:
    
            After sending this method any received method except
            Channel.Close-OK MUST be discarded.
    
        RULE:
    
            The peer sending this method MAY use a counter or timeout
            to detect failure of the other peer to respond correctly
            with Channel.Close-OK..
    
        PARAMETERS:
            reply_code: short
    
                The reply code. The AMQ reply codes are defined in AMQ
                RFC 011.
    
            reply_text: shortstr
    
                The localised reply text.  This text can be logged as an
                aid to resolving issues.
    
            class_id: short
    
                failing method class
    
                When the close is provoked by a method exception, this
                is the class of the method.
    
            method_id: short
    
                failing method ID
    
                When the close is provoked by a method exception, this
                is the ID of the method.
        """
        self.send_method(spec.Channel.CloseOk)
        if not self.connection.is_closing:
            self._do_revive()
            raise error_for_code(
>               reply_code, reply_text, (class_id, method_id), ChannelError,
            )
E           amqp.exceptions.PreconditionFailed: Queue.declare: (406) PRECONDITION_FAILED - inequivalent arg 'x-queue-type' for queue 'stats-file-download' in vhost '/': received the value 'quorum' of type 'longstr' but current is none

.tox/c1/lib/python3.6/site-packages/amqp/channel.py:280: PreconditionFailed
_ ERROR at setup of test_aggregations_delete[aggregated_file_download_events0] _

app = <Flask 'testapp'>
es = <Elasticsearch([{'host': 'elasticsearch', 'port': 9200}])>
mock_user_ctx = None
request = <SubRequest 'aggregated_file_download_events' for <Function test_aggregations_delete[aggregated_file_download_events0]>>

    @pytest.yield_fixture()
    def aggregated_file_download_events(app, es, mock_user_ctx, request):
        """Parametrized pre indexed sample events."""
        for t in current_search.put_templates(ignore=[400]):
            pass
>       generate_file_events(app=app, event_type="file-download", **request.param)

tests/conftest.py:910: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
tests/conftest.py:894: in generate_file_events
    process_events([event_type])
.tox/c1/lib/python3.6/site-packages/celery/local.py:191: in __call__
    return self._get_current_object()(*a, **kw)
.tox/c1/lib/python3.6/site-packages/celery/app/task.py:392: in __call__
    return self.run(*args, **kwargs)
invenio_stats/tasks.py:27: in process_events
    results.append((e, processor.run()))
invenio_stats/processors.py:243: in run
    chunk_size=50
.tox/c1/lib/python3.6/site-packages/elasticsearch/helpers/__init__.py:257: in bulk
    for ok, item in streaming_bulk(client, actions, **kwargs):
.tox/c1/lib/python3.6/site-packages/elasticsearch/helpers/__init__.py:180: in streaming_bulk
    client.transport.serializer):
.tox/c1/lib/python3.6/site-packages/elasticsearch/helpers/__init__.py:58: in _chunk_actions
    for action, data in actions:
invenio_stats/processors.py:192: in actionsiter
    for msg in self.queue.consume():
../invenio-queues/invenio_queues/queue.py:107: in consume
    with self.create_consumer() as consumer:
/usr/local/lib/python3.6/contextlib.py:81: in __enter__
    return next(self.gen)
../invenio-queues/invenio_queues/queue.py:96: in create_consumer
    yield self.consumer(conn)
../invenio-queues/invenio_queues/queue.py:83: in consumer
    no_ack=self.no_ack,
.tox/c1/src/kombu/kombu/compat.py:119: in __init__
    super(Consumer, self).__init__(self.backend, queue, **kwargs)
.tox/c1/src/kombu/kombu/messaging.py:386: in __init__
    self.revive(self.channel)
.tox/c1/src/kombu/kombu/compat.py:123: in revive
    super(Consumer, self).revive(channel)
.tox/c1/src/kombu/kombu/messaging.py:408: in revive
    self.declare()
.tox/c1/src/kombu/kombu/messaging.py:421: in declare
    queue.declare()
.tox/c1/src/kombu/kombu/entity.py:611: in declare
    self._create_queue(nowait=nowait, channel=channel)
.tox/c1/src/kombu/kombu/entity.py:620: in _create_queue
    self.queue_declare(nowait=nowait, passive=False, channel=channel)
.tox/c1/src/kombu/kombu/entity.py:655: in queue_declare
    nowait=nowait,
.tox/c1/lib/python3.6/site-packages/amqp/channel.py:1149: in queue_declare
    spec.Queue.DeclareOk, returns_tuple=True,
.tox/c1/lib/python3.6/site-packages/amqp/abstract_channel.py:88: in wait
    self.connection.drain_events(timeout=timeout)
.tox/c1/lib/python3.6/site-packages/amqp/connection.py:508: in drain_events
    while not self.blocking_read(timeout):
.tox/c1/lib/python3.6/site-packages/amqp/connection.py:514: in blocking_read
    return self.on_inbound_frame(frame)
.tox/c1/lib/python3.6/site-packages/amqp/method_framing.py:55: in on_frame
    callback(channel, method_sig, buf, None)
.tox/c1/lib/python3.6/site-packages/amqp/connection.py:521: in on_inbound_method
    method_sig, payload, content,
.tox/c1/lib/python3.6/site-packages/amqp/abstract_channel.py:145: in dispatch_method
    listener(*args)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <kombu.transport.pyamqp.Channel object at 0x7effe5150320>
reply_code = 406
reply_text = "PRECONDITION_FAILED - inequivalent arg 'x-queue-type' for queue 'stats-file-download' in vhost '/': received the value 'quorum' of type 'longstr' but current is none"
class_id = 50, method_id = 10

    def _on_close(self, reply_code, reply_text, class_id, method_id):
        """Request a channel close.
    
        This method indicates that the sender wants to close the
        channel. This may be due to internal conditions (e.g. a forced
        shut-down) or due to an error handling a specific method, i.e.
        an exception.  When a close is due to an exception, the sender
        provides the class and method id of the method which caused
        the exception.
    
        RULE:
    
            After sending this method any received method except
            Channel.Close-OK MUST be discarded.
    
        RULE:
    
            The peer sending this method MAY use a counter or timeout
            to detect failure of the other peer to respond correctly
            with Channel.Close-OK..
    
        PARAMETERS:
            reply_code: short
    
                The reply code. The AMQ reply codes are defined in AMQ
                RFC 011.
    
            reply_text: shortstr
    
                The localised reply text.  This text can be logged as an
                aid to resolving issues.
    
            class_id: short
    
                failing method class
    
                When the close is provoked by a method exception, this
                is the class of the method.
    
            method_id: short
    
                failing method ID
    
                When the close is provoked by a method exception, this
                is the ID of the method.
        """
        self.send_method(spec.Channel.CloseOk)
        if not self.connection.is_closing:
            self._do_revive()
            raise error_for_code(
>               reply_code, reply_text, (class_id, method_id), ChannelError,
            )
E           amqp.exceptions.PreconditionFailed: Queue.declare: (406) PRECONDITION_FAILED - inequivalent arg 'x-queue-type' for queue 'stats-file-download' in vhost '/': received the value 'quorum' of type 'longstr' but current is none

.tox/c1/lib/python3.6/site-packages/amqp/channel.py:280: PreconditionFailed
_ ERROR at setup of test_aggregations_list_bookmarks[aggregated_file_download_events0] _

app = <Flask 'testapp'>
es = <Elasticsearch([{'host': 'elasticsearch', 'port': 9200}])>
mock_user_ctx = None
request = <SubRequest 'aggregated_file_download_events' for <Function test_aggregations_list_bookmarks[aggregated_file_download_events0]>>

    @pytest.yield_fixture()
    def aggregated_file_download_events(app, es, mock_user_ctx, request):
        """Parametrized pre indexed sample events."""
        for t in current_search.put_templates(ignore=[400]):
            pass
>       generate_file_events(app=app, event_type="file-download", **request.param)

tests/conftest.py:910: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
tests/conftest.py:894: in generate_file_events
    process_events([event_type])
.tox/c1/lib/python3.6/site-packages/celery/local.py:191: in __call__
    return self._get_current_object()(*a, **kw)
.tox/c1/lib/python3.6/site-packages/celery/app/task.py:392: in __call__
    return self.run(*args, **kwargs)
invenio_stats/tasks.py:27: in process_events
    results.append((e, processor.run()))
invenio_stats/processors.py:243: in run
    chunk_size=50
.tox/c1/lib/python3.6/site-packages/elasticsearch/helpers/__init__.py:257: in bulk
    for ok, item in streaming_bulk(client, actions, **kwargs):
.tox/c1/lib/python3.6/site-packages/elasticsearch/helpers/__init__.py:180: in streaming_bulk
    client.transport.serializer):
.tox/c1/lib/python3.6/site-packages/elasticsearch/helpers/__init__.py:58: in _chunk_actions
    for action, data in actions:
invenio_stats/processors.py:192: in actionsiter
    for msg in self.queue.consume():
../invenio-queues/invenio_queues/queue.py:107: in consume
    with self.create_consumer() as consumer:
/usr/local/lib/python3.6/contextlib.py:81: in __enter__
    return next(self.gen)
../invenio-queues/invenio_queues/queue.py:96: in create_consumer
    yield self.consumer(conn)
../invenio-queues/invenio_queues/queue.py:83: in consumer
    no_ack=self.no_ack,
.tox/c1/src/kombu/kombu/compat.py:119: in __init__
    super(Consumer, self).__init__(self.backend, queue, **kwargs)
.tox/c1/src/kombu/kombu/messaging.py:386: in __init__
    self.revive(self.channel)
.tox/c1/src/kombu/kombu/compat.py:123: in revive
    super(Consumer, self).revive(channel)
.tox/c1/src/kombu/kombu/messaging.py:408: in revive
    self.declare()
.tox/c1/src/kombu/kombu/messaging.py:421: in declare
    queue.declare()
.tox/c1/src/kombu/kombu/entity.py:611: in declare
    self._create_queue(nowait=nowait, channel=channel)
.tox/c1/src/kombu/kombu/entity.py:620: in _create_queue
    self.queue_declare(nowait=nowait, passive=False, channel=channel)
.tox/c1/src/kombu/kombu/entity.py:655: in queue_declare
    nowait=nowait,
.tox/c1/lib/python3.6/site-packages/amqp/channel.py:1149: in queue_declare
    spec.Queue.DeclareOk, returns_tuple=True,
.tox/c1/lib/python3.6/site-packages/amqp/abstract_channel.py:88: in wait
    self.connection.drain_events(timeout=timeout)
.tox/c1/lib/python3.6/site-packages/amqp/connection.py:508: in drain_events
    while not self.blocking_read(timeout):
.tox/c1/lib/python3.6/site-packages/amqp/connection.py:514: in blocking_read
    return self.on_inbound_frame(frame)
.tox/c1/lib/python3.6/site-packages/amqp/method_framing.py:55: in on_frame
    callback(channel, method_sig, buf, None)
.tox/c1/lib/python3.6/site-packages/amqp/connection.py:521: in on_inbound_method
    method_sig, payload, content,
.tox/c1/lib/python3.6/site-packages/amqp/abstract_channel.py:145: in dispatch_method
    listener(*args)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <kombu.transport.pyamqp.Channel object at 0x7effe52de518>
reply_code = 406
reply_text = "PRECONDITION_FAILED - inequivalent arg 'x-queue-type' for queue 'stats-file-download' in vhost '/': received the value 'quorum' of type 'longstr' but current is none"
class_id = 50, method_id = 10

    def _on_close(self, reply_code, reply_text, class_id, method_id):
        """Request a channel close.
    
        This method indicates that the sender wants to close the
        channel. This may be due to internal conditions (e.g. a forced
        shut-down) or due to an error handling a specific method, i.e.
        an exception.  When a close is due to an exception, the sender
        provides the class and method id of the method which caused
        the exception.
    
        RULE:
    
            After sending this method any received method except
            Channel.Close-OK MUST be discarded.
    
        RULE:
    
            The peer sending this method MAY use a counter or timeout
            to detect failure of the other peer to respond correctly
            with Channel.Close-OK..
    
        PARAMETERS:
            reply_code: short
    
                The reply code. The AMQ reply codes are defined in AMQ
                RFC 011.
    
            reply_text: shortstr
    
                The localised reply text.  This text can be logged as an
                aid to resolving issues.
    
            class_id: short
    
                failing method class
    
                When the close is provoked by a method exception, this
                is the class of the method.
    
            method_id: short
    
                failing method ID
    
                When the close is provoked by a method exception, this
                is the ID of the method.
        """
        self.send_method(spec.Channel.CloseOk)
        if not self.connection.is_closing:
            self._do_revive()
            raise error_for_code(
>               reply_code, reply_text, (class_id, method_id), ChannelError,
            )
E           amqp.exceptions.PreconditionFailed: Queue.declare: (406) PRECONDITION_FAILED - inequivalent arg 'x-queue-type' for queue 'stats-file-download' in vhost '/': received the value 'quorum' of type 'longstr' but current is none

.tox/c1/lib/python3.6/site-packages/amqp/channel.py:280: PreconditionFailed
_ ERROR at setup of test_terms_query[mock_execute0-1-tests/data/ESTermsQuery_result01.json-aggregated_file_download_events0] _

app = <Flask 'testapp'>
es = <Elasticsearch([{'host': 'elasticsearch', 'port': 9200}])>
mock_user_ctx = None
request = <SubRequest 'aggregated_file_download_events' for <Function test_terms_query[mock_execute0-1-tests/data/ESTermsQuery_result01.json-aggregated_file_download_events0]>>

    @pytest.yield_fixture()
    def aggregated_file_download_events(app, es, mock_user_ctx, request):
        """Parametrized pre indexed sample events."""
        for t in current_search.put_templates(ignore=[400]):
            pass
>       generate_file_events(app=app, event_type="file-download", **request.param)

tests/conftest.py:910: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
tests/conftest.py:894: in generate_file_events
    process_events([event_type])
.tox/c1/lib/python3.6/site-packages/celery/local.py:191: in __call__
    return self._get_current_object()(*a, **kw)
.tox/c1/lib/python3.6/site-packages/celery/app/task.py:392: in __call__
    return self.run(*args, **kwargs)
invenio_stats/tasks.py:27: in process_events
    results.append((e, processor.run()))
invenio_stats/processors.py:243: in run
    chunk_size=50
.tox/c1/lib/python3.6/site-packages/elasticsearch/helpers/__init__.py:257: in bulk
    for ok, item in streaming_bulk(client, actions, **kwargs):
.tox/c1/lib/python3.6/site-packages/elasticsearch/helpers/__init__.py:180: in streaming_bulk
    client.transport.serializer):
.tox/c1/lib/python3.6/site-packages/elasticsearch/helpers/__init__.py:58: in _chunk_actions
    for action, data in actions:
invenio_stats/processors.py:192: in actionsiter
    for msg in self.queue.consume():
../invenio-queues/invenio_queues/queue.py:107: in consume
    with self.create_consumer() as consumer:
/usr/local/lib/python3.6/contextlib.py:81: in __enter__
    return next(self.gen)
../invenio-queues/invenio_queues/queue.py:96: in create_consumer
    yield self.consumer(conn)
../invenio-queues/invenio_queues/queue.py:83: in consumer
    no_ack=self.no_ack,
.tox/c1/src/kombu/kombu/compat.py:119: in __init__
    super(Consumer, self).__init__(self.backend, queue, **kwargs)
.tox/c1/src/kombu/kombu/messaging.py:386: in __init__
    self.revive(self.channel)
.tox/c1/src/kombu/kombu/compat.py:123: in revive
    super(Consumer, self).revive(channel)
.tox/c1/src/kombu/kombu/messaging.py:408: in revive
    self.declare()
.tox/c1/src/kombu/kombu/messaging.py:421: in declare
    queue.declare()
.tox/c1/src/kombu/kombu/entity.py:611: in declare
    self._create_queue(nowait=nowait, channel=channel)
.tox/c1/src/kombu/kombu/entity.py:620: in _create_queue
    self.queue_declare(nowait=nowait, passive=False, channel=channel)
.tox/c1/src/kombu/kombu/entity.py:655: in queue_declare
    nowait=nowait,
.tox/c1/lib/python3.6/site-packages/amqp/channel.py:1149: in queue_declare
    spec.Queue.DeclareOk, returns_tuple=True,
.tox/c1/lib/python3.6/site-packages/amqp/abstract_channel.py:88: in wait
    self.connection.drain_events(timeout=timeout)
.tox/c1/lib/python3.6/site-packages/amqp/connection.py:508: in drain_events
    while not self.blocking_read(timeout):
.tox/c1/lib/python3.6/site-packages/amqp/connection.py:514: in blocking_read
    return self.on_inbound_frame(frame)
.tox/c1/lib/python3.6/site-packages/amqp/method_framing.py:55: in on_frame
    callback(channel, method_sig, buf, None)
.tox/c1/lib/python3.6/site-packages/amqp/connection.py:521: in on_inbound_method
    method_sig, payload, content,
.tox/c1/lib/python3.6/site-packages/amqp/abstract_channel.py:145: in dispatch_method
    listener(*args)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <kombu.transport.pyamqp.Channel object at 0x7effe4ff18d0>
reply_code = 406
reply_text = "PRECONDITION_FAILED - inequivalent arg 'x-queue-type' for queue 'stats-file-download' in vhost '/': received the value 'quorum' of type 'longstr' but current is none"
class_id = 50, method_id = 10

    def _on_close(self, reply_code, reply_text, class_id, method_id):
        """Request a channel close.
    
        This method indicates that the sender wants to close the
        channel. This may be due to internal conditions (e.g. a forced
        shut-down) or due to an error handling a specific method, i.e.
        an exception.  When a close is due to an exception, the sender
        provides the class and method id of the method which caused
        the exception.
    
        RULE:
    
            After sending this method any received method except
            Channel.Close-OK MUST be discarded.
    
        RULE:
    
            The peer sending this method MAY use a counter or timeout
            to detect failure of the other peer to respond correctly
            with Channel.Close-OK..
    
        PARAMETERS:
            reply_code: short
    
                The reply code. The AMQ reply codes are defined in AMQ
                RFC 011.
    
            reply_text: shortstr
    
                The localised reply text.  This text can be logged as an
                aid to resolving issues.
    
            class_id: short
    
                failing method class
    
                When the close is provoked by a method exception, this
                is the class of the method.
    
            method_id: short
    
                failing method ID
    
                When the close is provoked by a method exception, this
                is the ID of the method.
        """
        self.send_method(spec.Channel.CloseOk)
        if not self.connection.is_closing:
            self._do_revive()
            raise error_for_code(
>               reply_code, reply_text, (class_id, method_id), ChannelError,
            )
E           amqp.exceptions.PreconditionFailed: Queue.declare: (406) PRECONDITION_FAILED - inequivalent arg 'x-queue-type' for queue 'stats-file-download' in vhost '/': received the value 'quorum' of type 'longstr' but current is none

.tox/c1/lib/python3.6/site-packages/amqp/channel.py:280: PreconditionFailed
_ ERROR at setup of test_terms_query[mock_execute1-1-tests/data/ESTermsQuery_result02.json-aggregated_file_download_events0] _

app = <Flask 'testapp'>
es = <Elasticsearch([{'host': 'elasticsearch', 'port': 9200}])>
mock_user_ctx = None
request = <SubRequest 'aggregated_file_download_events' for <Function test_terms_query[mock_execute1-1-tests/data/ESTermsQuery_result02.json-aggregated_file_download_events0]>>

    @pytest.yield_fixture()
    def aggregated_file_download_events(app, es, mock_user_ctx, request):
        """Parametrized pre indexed sample events."""
        for t in current_search.put_templates(ignore=[400]):
            pass
>       generate_file_events(app=app, event_type="file-download", **request.param)

tests/conftest.py:910: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
tests/conftest.py:894: in generate_file_events
    process_events([event_type])
.tox/c1/lib/python3.6/site-packages/celery/local.py:191: in __call__
    return self._get_current_object()(*a, **kw)
.tox/c1/lib/python3.6/site-packages/celery/app/task.py:392: in __call__
    return self.run(*args, **kwargs)
invenio_stats/tasks.py:27: in process_events
    results.append((e, processor.run()))
invenio_stats/processors.py:243: in run
    chunk_size=50
.tox/c1/lib/python3.6/site-packages/elasticsearch/helpers/__init__.py:257: in bulk
    for ok, item in streaming_bulk(client, actions, **kwargs):
.tox/c1/lib/python3.6/site-packages/elasticsearch/helpers/__init__.py:180: in streaming_bulk
    client.transport.serializer):
.tox/c1/lib/python3.6/site-packages/elasticsearch/helpers/__init__.py:58: in _chunk_actions
    for action, data in actions:
invenio_stats/processors.py:192: in actionsiter
    for msg in self.queue.consume():
../invenio-queues/invenio_queues/queue.py:107: in consume
    with self.create_consumer() as consumer:
/usr/local/lib/python3.6/contextlib.py:81: in __enter__
    return next(self.gen)
../invenio-queues/invenio_queues/queue.py:96: in create_consumer
    yield self.consumer(conn)
../invenio-queues/invenio_queues/queue.py:83: in consumer
    no_ack=self.no_ack,
.tox/c1/src/kombu/kombu/compat.py:119: in __init__
    super(Consumer, self).__init__(self.backend, queue, **kwargs)
.tox/c1/src/kombu/kombu/messaging.py:386: in __init__
    self.revive(self.channel)
.tox/c1/src/kombu/kombu/compat.py:123: in revive
    super(Consumer, self).revive(channel)
.tox/c1/src/kombu/kombu/messaging.py:408: in revive
    self.declare()
.tox/c1/src/kombu/kombu/messaging.py:421: in declare
    queue.declare()
.tox/c1/src/kombu/kombu/entity.py:611: in declare
    self._create_queue(nowait=nowait, channel=channel)
.tox/c1/src/kombu/kombu/entity.py:620: in _create_queue
    self.queue_declare(nowait=nowait, passive=False, channel=channel)
.tox/c1/src/kombu/kombu/entity.py:655: in queue_declare
    nowait=nowait,
.tox/c1/lib/python3.6/site-packages/amqp/channel.py:1149: in queue_declare
    spec.Queue.DeclareOk, returns_tuple=True,
.tox/c1/lib/python3.6/site-packages/amqp/abstract_channel.py:88: in wait
    self.connection.drain_events(timeout=timeout)
.tox/c1/lib/python3.6/site-packages/amqp/connection.py:508: in drain_events
    while not self.blocking_read(timeout):
.tox/c1/lib/python3.6/site-packages/amqp/connection.py:514: in blocking_read
    return self.on_inbound_frame(frame)
.tox/c1/lib/python3.6/site-packages/amqp/method_framing.py:55: in on_frame
    callback(channel, method_sig, buf, None)
.tox/c1/lib/python3.6/site-packages/amqp/connection.py:521: in on_inbound_method
    method_sig, payload, content,
.tox/c1/lib/python3.6/site-packages/amqp/abstract_channel.py:145: in dispatch_method
    listener(*args)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <kombu.transport.pyamqp.Channel object at 0x7effe48e85c0>
reply_code = 406
reply_text = "PRECONDITION_FAILED - inequivalent arg 'x-queue-type' for queue 'stats-file-download' in vhost '/': received the value 'quorum' of type 'longstr' but current is none"
class_id = 50, method_id = 10

    def _on_close(self, reply_code, reply_text, class_id, method_id):
        """Request a channel close.
    
        This method indicates that the sender wants to close the
        channel. This may be due to internal conditions (e.g. a forced
        shut-down) or due to an error handling a specific method, i.e.
        an exception.  When a close is due to an exception, the sender
        provides the class and method id of the method which caused
        the exception.
    
        RULE:
    
            After sending this method any received method except
            Channel.Close-OK MUST be discarded.
    
        RULE:
    
            The peer sending this method MAY use a counter or timeout
            to detect failure of the other peer to respond correctly
            with Channel.Close-OK..
    
        PARAMETERS:
            reply_code: short
    
                The reply code. The AMQ reply codes are defined in AMQ
                RFC 011.
    
            reply_text: shortstr
    
                The localised reply text.  This text can be logged as an
                aid to resolving issues.
    
            class_id: short
    
                failing method class
    
                When the close is provoked by a method exception, this
                is the class of the method.
    
            method_id: short
    
                failing method ID
    
                When the close is provoked by a method exception, this
                is the ID of the method.
        """
        self.send_method(spec.Channel.CloseOk)
        if not self.connection.is_closing:
            self._do_revive()
            raise error_for_code(
>               reply_code, reply_text, (class_id, method_id), ChannelError,
            )
E           amqp.exceptions.PreconditionFailed: Queue.declare: (406) PRECONDITION_FAILED - inequivalent arg 'x-queue-type' for queue 'stats-file-download' in vhost '/': received the value 'quorum' of type 'longstr' but current is none

.tox/c1/lib/python3.6/site-packages/amqp/channel.py:280: PreconditionFailed
_ ERROR at setup of test_terms_query[mock_execute2-16-tests/data/ESTermsQuery_result03.json-aggregated_file_download_events0] _

app = <Flask 'testapp'>
es = <Elasticsearch([{'host': 'elasticsearch', 'port': 9200}])>
mock_user_ctx = None
request = <SubRequest 'aggregated_file_download_events' for <Function test_terms_query[mock_execute2-16-tests/data/ESTermsQuery_result03.json-aggregated_file_download_events0]>>

    @pytest.yield_fixture()
    def aggregated_file_download_events(app, es, mock_user_ctx, request):
        """Parametrized pre indexed sample events."""
        for t in current_search.put_templates(ignore=[400]):
            pass
>       generate_file_events(app=app, event_type="file-download", **request.param)

tests/conftest.py:910: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
tests/conftest.py:894: in generate_file_events
    process_events([event_type])
.tox/c1/lib/python3.6/site-packages/celery/local.py:191: in __call__
    return self._get_current_object()(*a, **kw)
.tox/c1/lib/python3.6/site-packages/celery/app/task.py:392: in __call__
    return self.run(*args, **kwargs)
invenio_stats/tasks.py:27: in process_events
    results.append((e, processor.run()))
invenio_stats/processors.py:243: in run
    chunk_size=50
.tox/c1/lib/python3.6/site-packages/elasticsearch/helpers/__init__.py:257: in bulk
    for ok, item in streaming_bulk(client, actions, **kwargs):
.tox/c1/lib/python3.6/site-packages/elasticsearch/helpers/__init__.py:180: in streaming_bulk
    client.transport.serializer):
.tox/c1/lib/python3.6/site-packages/elasticsearch/helpers/__init__.py:58: in _chunk_actions
    for action, data in actions:
invenio_stats/processors.py:192: in actionsiter
    for msg in self.queue.consume():
../invenio-queues/invenio_queues/queue.py:107: in consume
    with self.create_consumer() as consumer:
/usr/local/lib/python3.6/contextlib.py:81: in __enter__
    return next(self.gen)
../invenio-queues/invenio_queues/queue.py:96: in create_consumer
    yield self.consumer(conn)
../invenio-queues/invenio_queues/queue.py:83: in consumer
    no_ack=self.no_ack,
.tox/c1/src/kombu/kombu/compat.py:119: in __init__
    super(Consumer, self).__init__(self.backend, queue, **kwargs)
.tox/c1/src/kombu/kombu/messaging.py:386: in __init__
    self.revive(self.channel)
.tox/c1/src/kombu/kombu/compat.py:123: in revive
    super(Consumer, self).revive(channel)
.tox/c1/src/kombu/kombu/messaging.py:408: in revive
    self.declare()
.tox/c1/src/kombu/kombu/messaging.py:421: in declare
    queue.declare()
.tox/c1/src/kombu/kombu/entity.py:611: in declare
    self._create_queue(nowait=nowait, channel=channel)
.tox/c1/src/kombu/kombu/entity.py:620: in _create_queue
    self.queue_declare(nowait=nowait, passive=False, channel=channel)
.tox/c1/src/kombu/kombu/entity.py:655: in queue_declare
    nowait=nowait,
.tox/c1/lib/python3.6/site-packages/amqp/channel.py:1149: in queue_declare
    spec.Queue.DeclareOk, returns_tuple=True,
.tox/c1/lib/python3.6/site-packages/amqp/abstract_channel.py:88: in wait
    self.connection.drain_events(timeout=timeout)
.tox/c1/lib/python3.6/site-packages/amqp/connection.py:508: in drain_events
    while not self.blocking_read(timeout):
.tox/c1/lib/python3.6/site-packages/amqp/connection.py:514: in blocking_read
    return self.on_inbound_frame(frame)
.tox/c1/lib/python3.6/site-packages/amqp/method_framing.py:55: in on_frame
    callback(channel, method_sig, buf, None)
.tox/c1/lib/python3.6/site-packages/amqp/connection.py:521: in on_inbound_method
    method_sig, payload, content,
.tox/c1/lib/python3.6/site-packages/amqp/abstract_channel.py:145: in dispatch_method
    listener(*args)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <kombu.transport.pyamqp.Channel object at 0x7effe4e0ccf8>
reply_code = 406
reply_text = "PRECONDITION_FAILED - inequivalent arg 'x-queue-type' for queue 'stats-file-download' in vhost '/': received the value 'quorum' of type 'longstr' but current is none"
class_id = 50, method_id = 10

    def _on_close(self, reply_code, reply_text, class_id, method_id):
        """Request a channel close.
    
        This method indicates that the sender wants to close the
        channel. This may be due to internal conditions (e.g. a forced
        shut-down) or due to an error handling a specific method, i.e.
        an exception.  When a close is due to an exception, the sender
        provides the class and method id of the method which caused
        the exception.
    
        RULE:
    
            After sending this method any received method except
            Channel.Close-OK MUST be discarded.
    
        RULE:
    
            The peer sending this method MAY use a counter or timeout
            to detect failure of the other peer to respond correctly
            with Channel.Close-OK..
    
        PARAMETERS:
            reply_code: short
    
                The reply code. The AMQ reply codes are defined in AMQ
                RFC 011.
    
            reply_text: shortstr
    
                The localised reply text.  This text can be logged as an
                aid to resolving issues.
    
            class_id: short
    
                failing method class
    
                When the close is provoked by a method exception, this
                is the class of the method.
    
            method_id: short
    
                failing method ID
    
                When the close is provoked by a method exception, this
                is the ID of the method.
        """
        self.send_method(spec.Channel.CloseOk)
        if not self.connection.is_closing:
            self._do_revive()
            raise error_for_code(
>               reply_code, reply_text, (class_id, method_id), ChannelError,
            )
E           amqp.exceptions.PreconditionFailed: Queue.declare: (406) PRECONDITION_FAILED - inequivalent arg 'x-queue-type' for queue 'stats-file-download' in vhost '/': received the value 'quorum' of type 'longstr' but current is none

.tox/c1/lib/python3.6/site-packages/amqp/channel.py:280: PreconditionFailed
_ ERROR at setup of test_query_file_reports_helper[aggregated_file_download_events0] _

app = <Flask 'testapp'>
es = <Elasticsearch([{'host': 'elasticsearch', 'port': 9200}])>
mock_user_ctx = None
request = <SubRequest 'aggregated_file_download_events' for <Function test_query_file_reports_helper[aggregated_file_download_events0]>>

    @pytest.yield_fixture()
    def aggregated_file_download_events(app, es, mock_user_ctx, request):
        """Parametrized pre indexed sample events."""
        for t in current_search.put_templates(ignore=[400]):
            pass
>       generate_file_events(app=app, event_type="file-download", **request.param)

tests/conftest.py:910: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
tests/conftest.py:894: in generate_file_events
    process_events([event_type])
.tox/c1/lib/python3.6/site-packages/celery/local.py:191: in __call__
    return self._get_current_object()(*a, **kw)
.tox/c1/lib/python3.6/site-packages/celery/app/task.py:392: in __call__
    return self.run(*args, **kwargs)
invenio_stats/tasks.py:27: in process_events
    results.append((e, processor.run()))
invenio_stats/processors.py:243: in run
    chunk_size=50
.tox/c1/lib/python3.6/site-packages/elasticsearch/helpers/__init__.py:257: in bulk
    for ok, item in streaming_bulk(client, actions, **kwargs):
.tox/c1/lib/python3.6/site-packages/elasticsearch/helpers/__init__.py:180: in streaming_bulk
    client.transport.serializer):
.tox/c1/lib/python3.6/site-packages/elasticsearch/helpers/__init__.py:58: in _chunk_actions
    for action, data in actions:
invenio_stats/processors.py:192: in actionsiter
    for msg in self.queue.consume():
../invenio-queues/invenio_queues/queue.py:107: in consume
    with self.create_consumer() as consumer:
/usr/local/lib/python3.6/contextlib.py:81: in __enter__
    return next(self.gen)
../invenio-queues/invenio_queues/queue.py:96: in create_consumer
    yield self.consumer(conn)
../invenio-queues/invenio_queues/queue.py:83: in consumer
    no_ack=self.no_ack,
.tox/c1/src/kombu/kombu/compat.py:119: in __init__
    super(Consumer, self).__init__(self.backend, queue, **kwargs)
.tox/c1/src/kombu/kombu/messaging.py:386: in __init__
    self.revive(self.channel)
.tox/c1/src/kombu/kombu/compat.py:123: in revive
    super(Consumer, self).revive(channel)
.tox/c1/src/kombu/kombu/messaging.py:408: in revive
    self.declare()
.tox/c1/src/kombu/kombu/messaging.py:421: in declare
    queue.declare()
.tox/c1/src/kombu/kombu/entity.py:611: in declare
    self._create_queue(nowait=nowait, channel=channel)
.tox/c1/src/kombu/kombu/entity.py:620: in _create_queue
    self.queue_declare(nowait=nowait, passive=False, channel=channel)
.tox/c1/src/kombu/kombu/entity.py:655: in queue_declare
    nowait=nowait,
.tox/c1/lib/python3.6/site-packages/amqp/channel.py:1149: in queue_declare
    spec.Queue.DeclareOk, returns_tuple=True,
.tox/c1/lib/python3.6/site-packages/amqp/abstract_channel.py:88: in wait
    self.connection.drain_events(timeout=timeout)
.tox/c1/lib/python3.6/site-packages/amqp/connection.py:508: in drain_events
    while not self.blocking_read(timeout):
.tox/c1/lib/python3.6/site-packages/amqp/connection.py:514: in blocking_read
    return self.on_inbound_frame(frame)
.tox/c1/lib/python3.6/site-packages/amqp/method_framing.py:55: in on_frame
    callback(channel, method_sig, buf, None)
.tox/c1/lib/python3.6/site-packages/amqp/connection.py:521: in on_inbound_method
    method_sig, payload, content,
.tox/c1/lib/python3.6/site-packages/amqp/abstract_channel.py:145: in dispatch_method
    listener(*args)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <kombu.transport.pyamqp.Channel object at 0x7effe4c7c668>
reply_code = 406
reply_text = "PRECONDITION_FAILED - inequivalent arg 'x-queue-type' for queue 'stats-file-download' in vhost '/': received the value 'quorum' of type 'longstr' but current is none"
class_id = 50, method_id = 10

    def _on_close(self, reply_code, reply_text, class_id, method_id):
        """Request a channel close.
    
        This method indicates that the sender wants to close the
        channel. This may be due to internal conditions (e.g. a forced
        shut-down) or due to an error handling a specific method, i.e.
        an exception.  When a close is due to an exception, the sender
        provides the class and method id of the method which caused
        the exception.
    
        RULE:
    
            After sending this method any received method except
            Channel.Close-OK MUST be discarded.
    
        RULE:
    
            The peer sending this method MAY use a counter or timeout
            to detect failure of the other peer to respond correctly
            with Channel.Close-OK..
    
        PARAMETERS:
            reply_code: short
    
                The reply code. The AMQ reply codes are defined in AMQ
                RFC 011.
    
            reply_text: shortstr
    
                The localised reply text.  This text can be logged as an
                aid to resolving issues.
    
            class_id: short
    
                failing method class
    
                When the close is provoked by a method exception, this
                is the class of the method.
    
            method_id: short
    
                failing method ID
    
                When the close is provoked by a method exception, this
                is the ID of the method.
        """
        self.send_method(spec.Channel.CloseOk)
        if not self.connection.is_closing:
            self._do_revive()
            raise error_for_code(
>               reply_code, reply_text, (class_id, method_id), ChannelError,
            )
E           amqp.exceptions.PreconditionFailed: Queue.declare: (406) PRECONDITION_FAILED - inequivalent arg 'x-queue-type' for queue 'stats-file-download' in vhost '/': received the value 'quorum' of type 'longstr' but current is none

.tox/c1/lib/python3.6/site-packages/amqp/channel.py:280: PreconditionFailed
=================================== FAILURES ===================================
_____________________________ test_events_process ______________________________

app = <Flask 'testapp'>
script_info = <flask.cli.ScriptInfo object at 0x7effe53b3780>
es = <Elasticsearch([{'host': 'elasticsearch', 'port': 9200}])>
event_queues = None

    def test_events_process(app, script_info, es, event_queues):
        """Test "events process" CLI command."""
        search = Search(using=es)
        runner = CliRunner()
    
        # Invalid argument
        result = runner.invoke(
            stats, ['events', 'process', 'invalid-event-type', '--eager'],
            obj=script_info)
        assert result.exit_code == 2
        assert 'Invalid event type(s):' in result.output
    
        current_stats.publish(
            'file-download',
            [_create_file_download_event(date) for date in
             [(2018, 1, 1, 10), (2018, 1, 1, 12), (2018, 1, 1, 14)]])
        current_stats.publish(
            'record-view',
            [_create_record_view_event(date) for date in
             [(2018, 1, 1, 10), (2018, 1, 1, 12), (2018, 1, 1, 14)]])
    
        result = runner.invoke(
            stats, ['events', 'process', 'file-download', '--eager'],
            obj=script_info)
>       assert result.exit_code == 0
E       assert -1 == 0
E         --1
E         +0

tests/test_cli.py:48: AssertionError
______________________________ test_double_clicks ______________________________

app = <Flask 'testapp'>, mock_event_queue = <Mock id='139637510768960'>
es = <Elasticsearch([{'host': 'elasticsearch', 'port': 9200}])>

    def test_double_clicks(app, mock_event_queue, es):
        """Test that events occurring within a time window are counted as 1."""
        event_type = 'file-download'
        events = [_create_file_download_event(date) for date in
                  [(2000, 6, 1, 10, 0, 10),
                   (2000, 6, 1, 10, 0, 11),
                   (2000, 6, 1, 10, 0, 19),
                   (2000, 6, 1, 10, 0, 22)]]
        current_queues.declare()
        current_stats.publish(event_type, events)
>       process_events(['file-download'])

tests/test_processors.py:258: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
.tox/c1/lib/python3.6/site-packages/celery/local.py:191: in __call__
    return self._get_current_object()(*a, **kw)
.tox/c1/lib/python3.6/site-packages/celery/app/task.py:392: in __call__
    return self.run(*args, **kwargs)
invenio_stats/tasks.py:27: in process_events
    results.append((e, processor.run()))
invenio_stats/processors.py:243: in run
    chunk_size=50
.tox/c1/lib/python3.6/site-packages/elasticsearch/helpers/__init__.py:257: in bulk
    for ok, item in streaming_bulk(client, actions, **kwargs):
.tox/c1/lib/python3.6/site-packages/elasticsearch/helpers/__init__.py:180: in streaming_bulk
    client.transport.serializer):
.tox/c1/lib/python3.6/site-packages/elasticsearch/helpers/__init__.py:58: in _chunk_actions
    for action, data in actions:
invenio_stats/processors.py:192: in actionsiter
    for msg in self.queue.consume():
../invenio-queues/invenio_queues/queue.py:107: in consume
    with self.create_consumer() as consumer:
/usr/local/lib/python3.6/contextlib.py:81: in __enter__
    return next(self.gen)
../invenio-queues/invenio_queues/queue.py:96: in create_consumer
    yield self.consumer(conn)
../invenio-queues/invenio_queues/queue.py:83: in consumer
    no_ack=self.no_ack,
.tox/c1/src/kombu/kombu/compat.py:119: in __init__
    super(Consumer, self).__init__(self.backend, queue, **kwargs)
.tox/c1/src/kombu/kombu/messaging.py:386: in __init__
    self.revive(self.channel)
.tox/c1/src/kombu/kombu/compat.py:123: in revive
    super(Consumer, self).revive(channel)
.tox/c1/src/kombu/kombu/messaging.py:408: in revive
    self.declare()
.tox/c1/src/kombu/kombu/messaging.py:421: in declare
    queue.declare()
.tox/c1/src/kombu/kombu/entity.py:611: in declare
    self._create_queue(nowait=nowait, channel=channel)
.tox/c1/src/kombu/kombu/entity.py:620: in _create_queue
    self.queue_declare(nowait=nowait, passive=False, channel=channel)
.tox/c1/src/kombu/kombu/entity.py:655: in queue_declare
    nowait=nowait,
.tox/c1/lib/python3.6/site-packages/amqp/channel.py:1149: in queue_declare
    spec.Queue.DeclareOk, returns_tuple=True,
.tox/c1/lib/python3.6/site-packages/amqp/abstract_channel.py:88: in wait
    self.connection.drain_events(timeout=timeout)
.tox/c1/lib/python3.6/site-packages/amqp/connection.py:508: in drain_events
    while not self.blocking_read(timeout):
.tox/c1/lib/python3.6/site-packages/amqp/connection.py:514: in blocking_read
    return self.on_inbound_frame(frame)
.tox/c1/lib/python3.6/site-packages/amqp/method_framing.py:55: in on_frame
    callback(channel, method_sig, buf, None)
.tox/c1/lib/python3.6/site-packages/amqp/connection.py:521: in on_inbound_method
    method_sig, payload, content,
.tox/c1/lib/python3.6/site-packages/amqp/abstract_channel.py:145: in dispatch_method
    listener(*args)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <kombu.transport.pyamqp.Channel object at 0x7effe43cc470>
reply_code = 406
reply_text = "PRECONDITION_FAILED - inequivalent arg 'x-queue-type' for queue 'stats-file-download' in vhost '/': received the value 'quorum' of type 'longstr' but current is none"
class_id = 50, method_id = 10

    def _on_close(self, reply_code, reply_text, class_id, method_id):
        """Request a channel close.
    
        This method indicates that the sender wants to close the
        channel. This may be due to internal conditions (e.g. a forced
        shut-down) or due to an error handling a specific method, i.e.
        an exception.  When a close is due to an exception, the sender
        provides the class and method id of the method which caused
        the exception.
    
        RULE:
    
            After sending this method any received method except
            Channel.Close-OK MUST be discarded.
    
        RULE:
    
            The peer sending this method MAY use a counter or timeout
            to detect failure of the other peer to respond correctly
            with Channel.Close-OK..
    
        PARAMETERS:
            reply_code: short
    
                The reply code. The AMQ reply codes are defined in AMQ
                RFC 011.
    
            reply_text: shortstr
    
                The localised reply text.  This text can be logged as an
                aid to resolving issues.
    
            class_id: short
    
                failing method class
    
                When the close is provoked by a method exception, this
                is the class of the method.
    
            method_id: short
    
                failing method ID
    
                When the close is provoked by a method exception, this
                is the ID of the method.
        """
        self.send_method(spec.Channel.CloseOk)
        if not self.connection.is_closing:
            self._do_revive()
            raise error_for_code(
>               reply_code, reply_text, (class_id, method_id), ChannelError,
            )
E           amqp.exceptions.PreconditionFailed: Queue.declare: (406) PRECONDITION_FAILED - inequivalent arg 'x-queue-type' for queue 'stats-file-download' in vhost '/': received the value 'quorum' of type 'longstr' but current is none

.tox/c1/lib/python3.6/site-packages/amqp/channel.py:280: PreconditionFailed
__________________________ test_date_histogram_query ___________________________

app = <Flask 'testapp'>

    def test_date_histogram_query(app):
        config_num = 8      # query_name='bucket-file-download-histogram'
        query_configs = register_queries()
        histogram_config = query_configs[config_num]['query_config']
        # __init__
        with pytest.raises(ValueError):
            ESDateHistogramQuery(
                query_name='test_total_count',
                **histogram_config,
                metric_fields={'value': ('test', '', {})}
            )
    
        # validate_arguments
        query = ESDateHistogramQuery(
            query_name='test_total_count',
            **histogram_config
        )
        with pytest.raises(InvalidRequestInputError):
            query.validate_arguments('test_interval', None, None)
        with pytest.raises(InvalidRequestInputError):
            query.validate_arguments('year', None, None)
        assert not query.validate_arguments('year', None, None, bucket_id='test_id', file_key='test_key')
    
        # build_query
        query = ESDateHistogramQuery(
            query_name='test_total_count',
            **histogram_config
        )
>       assert query.build_query('month', datetime.date(2023, 1, 1), datetime.date(2023, 3, 31)).to_dict() == {'query': {'bool': {'filter': [{'range': {'timestamp': {'gte': '2023-01-01', 'lte': '2023-03-31'}}}]}}, 'aggs': {'histogram': {'date_histogram': {'field': 'timestamp', 'interval': 'month', 'time_zone': 'Asia/Tokyo'}, 'aggs': {'value': {'sum': {'field': 'count'}}, 'top_hit': {'top_hits': {'size': 1, 'sort': {'timestamp': 'desc'}}}}}}, 'from': 0, 'size': 0}
E       AssertionError: assert {'aggs': {'hi...}}, 'size': 0} == {'aggs': {'his...}}, 'size': 0}
E         Common items:
E         {'from': 0,
E          'query': {'bool': {'filter': [{'range': {'timestamp': {'gte': '2023-01-01',
E                                                                 'lte': '2023-03-31'}}}]}},
E          'size': 0}
E         Differing items:
E         {'aggs': {'histogram': {'aggs': {'top_hit': {'top_hits': {'size': 1, 'sort': {...}}}, 'value': {'sum': {'field': 'count'}}}, 'date_histogram': {'field': 'timestamp', 'interval': 'month', 'time_zone': 'UTC'}}}} != {'aggs': {'histogram': {'aggs': {'top_hit': {'top_hits': {'size': 1, 'sort': {...}}}, 'value': {'sum': {'field': 'count'}}}, 'date_histogram': {'field': 'timestamp', 'interval': 'month', 'time_zone': 'Asia/Tokyo'}}}}
E         Full diff:
E         {'aggs': {'histogram': {'aggs': {'top_hit': {'top_hits': {'size': 1,
E         'sort': {'timestamp': 'desc'}}},
E         'value': {'sum': {'field': 'count'}}},
E         'date_histogram': {'field': 'timestamp',
E         'interval': 'month',
E         -                                            'time_zone': 'UTC'}}},
E         ?                                                          ^ ^
E         +                                            'time_zone': 'Asia/Tokyo'}}},
E         ?                                                          ^^^^^ ^^^^
E         'from': 0,
E         'query': {'bool': {'filter': [{'range': {'timestamp': {'gte': '2023-01-01',
E         'lte': '2023-03-31'}}}]}},
E         'size': 0}

tests/test_queries.py:76: AssertionError
______________________________ test_terms_query2 _______________________________

app = <Flask 'testapp'>

    def test_terms_query2(app):
        config_num = 0        # query_name='get-celery-task-report'
        query_configs = register_queries()
        terms_config = query_configs[config_num]['query_config']
    
        # validate_arguments
        query = ESTermsQuery(
            query_name='test_total_count',
            **terms_config
        )
        with pytest.raises(InvalidRequestInputError):
            query.validate_arguments(None, None)
        assert not query.validate_arguments(None, None, task_name='task1')
    
        # build_query
        query = ESTermsQuery(
            query_name='test_total_count',
            **terms_config,
            query_modifiers=[filter_robots]
        )
>       assert query.build_query(datetime.datetime(2023, 1, 1), None).to_dict() == {'query': {'bool': {'filter': [{'range': {'timestamp': {'gte': '2023-01-01T00:00:00', 'time_zone': 'Asia/Tokyo'}}}, {'term': {'is_robot': False}}]}}, 'aggs': {'value': {'sum': {'field': 'count'}}, 'task_id': {'terms': {'field': 'task_id', 'size': 6000}, 'aggs': {'value': {'sum': {'field': 'count'}}, 'task_name': {'terms': {'field': 'task_name', 'size': 6000}, 'aggs': {'value': {'sum': {'field': 'count'}}, 'start_time': {'terms': {'field': 'start_time', 'size': 6000}, 'aggs': {'value': {'sum': {'field': 'count'}}, 'end_time': {'terms': {'field': 'end_time', 'size': 6000}, 'aggs': {'value': {'sum': {'field': 'count'}}, 'total_records': {'terms': {'field': 'total_records', 'size': 6000}, 'aggs': {'value': {'sum': {'field': 'count'}}, 'task_state': {'terms': {'field': 'task_state', 'size': 6000}, 'aggs': {'value': {'sum': {'field': 'count'}}}}}}}}}}}}}}}, 'from': 0, 'size': 0}
E       AssertionError: assert {'aggs': {'ta...}}, 'size': 0} == {'aggs': {'tas...}}, 'size': 0}
E         Common items:
E         {'aggs': {'task_id': {'aggs': {'task_name': {'aggs': {'start_time': {'aggs': {'end_time': {'aggs': {'total_records': {'aggs': {'task_state': {'aggs': {'value': {'sum': {'field': 'count'}}},
E                                                                                                                                                       'terms': {'field': 'task_state',
E                                                                                                                                                                 'size': 6000}},
E                                                                                                                                        'value': {'sum': {'field': 'count'}}},
E                                                                                                                               'terms': {'field': 'total_records',
E                                                                                                                                         'size': 6000}},
E                                                                                                             'value': {'sum': {'field': 'count'}}},
E                                                                                                    'terms': {'field': 'end_time',
E                                                                                                              'size': 6000}},
E                                                                                       'value': {'sum': {'field': 'count'}}},
E                                                                              'terms': {'field': 'start_time',
E                                                                                        'size': 6000}},
E                                                               'value': {'sum': {'field': 'count'}}},
E                                                      'terms': {'field': 'task_name',
E                                                                'size': 6000}},
E                                        'value': {'sum': {'field': 'count'}}},
E                               'terms': {'field': 'task_id', 'size': 6000}},
E                   'value': {'sum': {'field': 'count'}}},
E          'from': 0,
E          'size': 0}
E         Differing items:
E         {'query': {'bool': {'filter': [{'range': {'timestamp': {...}}}, {'term': {'is_robot': False}}]}}} != {'query': {'bool': {'filter': [{'range': {'timestamp': {...}}}, {'term': {'is_robot': False}}]}}}
E         Full diff:
E         {'aggs': {'task_id': {'aggs': {'task_name': {'aggs': {'start_time': {'aggs': {'end_time': {'aggs': {'total_records': {'aggs': {'task_state': {'aggs': {'value': {'sum': {'field': 'count'}}},
E         'terms': {'field': 'task_state',
E         'size': 6000}},
E         'value': {'sum': {'field': 'count'}}},
E         'terms': {'field': 'total_records',
E         'size': 6000}},
E         'value': {'sum': {'field': 'count'}}},
E         'terms': {'field': 'end_time',
E         'size': 6000}},
E         'value': {'sum': {'field': 'count'}}},
E         'terms': {'field': 'start_time',
E         'size': 6000}},
E         'value': {'sum': {'field': 'count'}}},
E         'terms': {'field': 'task_name',
E         'size': 6000}},
E         'value': {'sum': {'field': 'count'}}},
E         'terms': {'field': 'task_id', 'size': 6000}},
E         'value': {'sum': {'field': 'count'}}},
E         'from': 0,
E         'query': {'bool': {'filter': [{'range': {'timestamp': {'gte': '2023-01-01T00:00:00',
E         -                                                         'time_zone': 'UTC'}}},
E         ?                                                                       ^ ^
E         +                                                         'time_zone': 'Asia/Tokyo'}}},
E         ?                                                                       ^^^^^ ^^^^
E         {'term': {'is_robot': False}}]}},
E         'size': 0}

tests/test_queries.py:208: AssertionError
__________________________ test_weko_file_stats_query __________________________

app = <Flask 'testapp'>

    def test_weko_file_stats_query(app):
        config_num = 9        # query_name='bucket-file-download-total'
        query_configs = register_queries()
        filestats_config = query_configs[config_num]['query_config']
    
        # build_query
        test_config = copy.deepcopy(filestats_config)
        test_config.pop('main_query')
        test_config.pop('aggregated_fields')
        query = ESWekoFileStatsQuery(
            query_name='test_total_count',
            **test_config,
            query_modifiers=[filter_robots]
        )
>       assert query.build_query(datetime.datetime(2023, 1, 1), None).to_dict() == {'query': {'bool': {'filter': [{'range': {'timestamp': {'gte': '2023-01-01T00:00:00', 'time_zone': 'Asia/Tokyo'}}}, {'term': {'is_robot': False}}]}}, 'aggs': {'value': {'sum': {'field': 'count'}}}, 'from': 0, 'size': 0}
E       AssertionError: assert {'aggs': {'va...}}, 'size': 0} == {'aggs': {'val...}}, 'size': 0}
E         Common items:
E         {'aggs': {'value': {'sum': {'field': 'count'}}}, 'from': 0, 'size': 0}
E         Differing items:
E         {'query': {'bool': {'filter': [{'range': {'timestamp': {...}}}, {'term': {'is_robot': False}}]}}} != {'query': {'bool': {'filter': [{'range': {'timestamp': {...}}}, {'term': {'is_robot': False}}]}}}
E         Full diff:
E         {'aggs': {'value': {'sum': {'field': 'count'}}},
E         'from': 0,
E         'query': {'bool': {'filter': [{'range': {'timestamp': {'gte': '2023-01-01T00:00:00',
E         -                                                         'time_zone': 'UTC'}}},
E         ?                                                                       ^ ^
E         +                                                         'time_zone': 'Asia/Tokyo'}}},
E         ?                                                                       ^^^^^ ^^^^
E         {'term': {'is_robot': False}}]}},
E         'size': 0}

tests/test_queries.py:288: AssertionError
____________________________ test_weko_terms_query _____________________________

app = <Flask 'testapp'>

    def test_weko_terms_query(app):
        config_num = 1        # query_name='get-search-report'
        query_configs = register_queries()
        weko_terms_config = query_configs[config_num]['query_config']
    
        # build_query
        test_config = copy.deepcopy(weko_terms_config)
        test_config.pop('group_fields')
        test_config['copy_fields'] = {
            'record_id': 'record_id',
            'test_value': lambda res, data: data['test_value']
        }
        query = ESWekoTermsQuery(
            query_name='test_total_count',
            **test_config,
            query_modifiers=[filter_robots]
        )
>       assert query.build_query(datetime.datetime(2023, 1, 1), None).to_dict() == {'query': {'bool': {'filter': [{'range': {'timestamp': {'gte': '2023-01-01T00:00:00', 'time_zone': 'Asia/Tokyo'}}}, {'term': {'is_robot': False}}]}}, 'aggs': {'value': {'sum': {'field': 'count'}}, 'top_hit': {'top_hits': {'size': 1, 'sort': {'timestamp': 'desc'}}}}, 'from': 0, 'size': 0}
E       AssertionError: assert {'aggs': {'to...}}, 'size': 0} == {'aggs': {'top...}}, 'size': 0}
E         Common items:
E         {'aggs': {'top_hit': {'top_hits': {'size': 1, 'sort': {'timestamp': 'desc'}}},
E                   'value': {'sum': {'field': 'count'}}},
E          'from': 0,
E          'size': 0}
E         Differing items:
E         {'query': {'bool': {'filter': [{'range': {'timestamp': {...}}}, {'term': {'is_robot': False}}]}}} != {'query': {'bool': {'filter': [{'range': {'timestamp': {...}}}, {'term': {'is_robot': False}}]}}}
E         Full diff:
E         {'aggs': {'top_hit': {'top_hits': {'size': 1, 'sort': {'timestamp': 'desc'}}},
E         'value': {'sum': {'field': 'count'}}},
E         'from': 0,
E         'query': {'bool': {'filter': [{'range': {'timestamp': {'gte': '2023-01-01T00:00:00',
E         -                                                         'time_zone': <function get_timezone at 0x7f0015f7e620>}}},
E         ?                                                                      ^^^^^^  ^^^^^^^^^^^ ^^^^^^^^^^^^^^^^^^^^^
E         +                                                         'time_zone': 'Asia/Tokyo'}}},
E         ?                                                                      ^^^ +++ ^^ ^
E         {'term': {'is_robot': False}}]}},
E         'size': 0}

tests/test_queries.py:318: AssertionError
_________________________ test_ESWekoFileRankingQuery __________________________

self = <elasticsearch.serializer.JSONSerializer object at 0x7f0011e618d0>
data = {'aggs': {'download_ranking': {'terms': {'field': 'file_key'}}}, 'query': {'bool': {'filter': [{'term': {'item_id': {...}}}, {'terms': {'root_file_id': [...]}}, {'range': {'timestamp': {...}}}]}}, 'size': 0}

    def dumps(self, data):
        # don't serialize strings
        if isinstance(data, string_types):
            return data
    
        try:
            return json.dumps(
                data,
                default=self.default,
                ensure_ascii=False,
>               separators=(',', ':'),
            )

.tox/c1/lib/python3.6/site-packages/elasticsearch/serializer.py:52: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

obj = {'aggs': {'download_ranking': {'terms': {'field': 'file_key'}}}, 'query': {'bool': {'filter': [{'term': {'item_id': {...}}}, {'terms': {'root_file_id': [...]}}, {'range': {'timestamp': {...}}}]}}, 'size': 0}
skipkeys = False, ensure_ascii = False, check_circular = True, allow_nan = True
cls = <class 'simplejson.encoder.JSONEncoder'>, indent = None
separators = (',', ':'), encoding = 'utf-8'
default = <bound method JSONSerializer.default of <elasticsearch.serializer.JSONSerializer object at 0x7f0011e618d0>>
use_decimal = True, namedtuple_as_object = True, tuple_as_array = True
bigint_as_string = False, sort_keys = False, item_sort_key = None
for_json = False, ignore_nan = False, int_as_string_bitcount = None
iterable_as_array = False, kw = {}

    def dumps(obj, skipkeys=False, ensure_ascii=True, check_circular=True,
              allow_nan=True, cls=None, indent=None, separators=None,
              encoding='utf-8', default=None, use_decimal=True,
              namedtuple_as_object=True, tuple_as_array=True,
              bigint_as_string=False, sort_keys=False, item_sort_key=None,
              for_json=False, ignore_nan=False, int_as_string_bitcount=None,
              iterable_as_array=False, **kw):
        """Serialize ``obj`` to a JSON formatted ``str``.
    
        If ``skipkeys`` is false then ``dict`` keys that are not basic types
        (``str``, ``unicode``, ``int``, ``long``, ``float``, ``bool``, ``None``)
        will be skipped instead of raising a ``TypeError``.
    
        If ``ensure_ascii`` is false, then the return value will be a
        ``unicode`` instance subject to normal Python ``str`` to ``unicode``
        coercion rules instead of being escaped to an ASCII ``str``.
    
        If ``check_circular`` is false, then the circular reference check
        for container types will be skipped and a circular reference will
        result in an ``OverflowError`` (or worse).
    
        If ``allow_nan`` is false, then it will be a ``ValueError`` to
        serialize out of range ``float`` values (``nan``, ``inf``, ``-inf``) in
        strict compliance of the JSON specification, instead of using the
        JavaScript equivalents (``NaN``, ``Infinity``, ``-Infinity``).
    
        If ``indent`` is a string, then JSON array elements and object members
        will be pretty-printed with a newline followed by that string repeated
        for each level of nesting. ``None`` (the default) selects the most compact
        representation without any newlines. For backwards compatibility with
        versions of simplejson earlier than 2.1.0, an integer is also accepted
        and is converted to a string with that many spaces.
    
        If specified, ``separators`` should be an
        ``(item_separator, key_separator)`` tuple.  The default is ``(', ', ': ')``
        if *indent* is ``None`` and ``(',', ': ')`` otherwise.  To get the most
        compact JSON representation, you should specify ``(',', ':')`` to eliminate
        whitespace.
    
        ``encoding`` is the character encoding for str instances, default is UTF-8.
    
        ``default(obj)`` is a function that should return a serializable version
        of obj or raise TypeError. The default simply raises TypeError.
    
        If *use_decimal* is true (default: ``True``) then decimal.Decimal
        will be natively serialized to JSON with full precision.
    
        If *namedtuple_as_object* is true (default: ``True``),
        :class:`tuple` subclasses with ``_asdict()`` methods will be encoded
        as JSON objects.
    
        If *tuple_as_array* is true (default: ``True``),
        :class:`tuple` (and subclasses) will be encoded as JSON arrays.
    
        If *iterable_as_array* is true (default: ``False``),
        any object not in the above table that implements ``__iter__()``
        will be encoded as a JSON array.
    
        If *bigint_as_string* is true (not the default), ints 2**53 and higher
        or lower than -2**53 will be encoded as strings. This is to avoid the
        rounding that happens in Javascript otherwise.
    
        If *int_as_string_bitcount* is a positive number (n), then int of size
        greater than or equal to 2**n or lower than or equal to -2**n will be
        encoded as strings.
    
        If specified, *item_sort_key* is a callable used to sort the items in
        each dictionary. This is useful if you want to sort items other than
        in alphabetical order by key. This option takes precendence over
        *sort_keys*.
    
        If *sort_keys* is true (default: ``False``), the output of dictionaries
        will be sorted by item.
    
        If *for_json* is true (default: ``False``), objects with a ``for_json()``
        method will use the return value of that method for encoding as JSON
        instead of the object.
    
        If *ignore_nan* is true (default: ``False``), then out of range
        :class:`float` values (``nan``, ``inf``, ``-inf``) will be serialized as
        ``null`` in compliance with the ECMA-262 specification. If true, this will
        override *allow_nan*.
    
        To use a custom ``JSONEncoder`` subclass (e.g. one that overrides the
        ``.default()`` method to serialize additional types), specify it with
        the ``cls`` kwarg. NOTE: You should use *default* instead of subclassing
        whenever possible.
    
        """
        # cached encoder
        if (not skipkeys and ensure_ascii and
            check_circular and allow_nan and
            cls is None and indent is None and separators is None and
            encoding == 'utf-8' and default is None and use_decimal
            and namedtuple_as_object and tuple_as_array and not iterable_as_array
            and not bigint_as_string and not sort_keys
            and not item_sort_key and not for_json
            and not ignore_nan and int_as_string_bitcount is None
            and not kw
        ):
            return _default_encoder.encode(obj)
        if cls is None:
            cls = JSONEncoder
        return cls(
            skipkeys=skipkeys, ensure_ascii=ensure_ascii,
            check_circular=check_circular, allow_nan=allow_nan, indent=indent,
            separators=separators, encoding=encoding, default=default,
            use_decimal=use_decimal,
            namedtuple_as_object=namedtuple_as_object,
            tuple_as_array=tuple_as_array,
            iterable_as_array=iterable_as_array,
            bigint_as_string=bigint_as_string,
            sort_keys=sort_keys,
            item_sort_key=item_sort_key,
            for_json=for_json,
            ignore_nan=ignore_nan,
            int_as_string_bitcount=int_as_string_bitcount,
>           **kw).encode(obj)

.tox/c1/lib/python3.6/site-packages/simplejson/__init__.py:398: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <simplejson.encoder.JSONEncoder object at 0x7effe4a18860>
o = {'aggs': {'download_ranking': {'terms': {'field': 'file_key'}}}, 'query': {'bool': {'filter': [{'term': {'item_id': {...}}}, {'terms': {'root_file_id': [...]}}, {'range': {'timestamp': {...}}}]}}, 'size': 0}

    def encode(self, o):
        """Return a JSON string representation of a Python data structure.
    
        >>> from simplejson import JSONEncoder
        >>> JSONEncoder().encode({"foo": ["bar", "baz"]})
        '{"foo": ["bar", "baz"]}'
    
        """
        # This is for extremely simple cases and benchmarks.
        if isinstance(o, binary_type):
            _encoding = self.encoding
            if (_encoding is not None and not (_encoding == 'utf-8')):
                o = o.decode(_encoding)
        if isinstance(o, string_types):
            if self.ensure_ascii:
                return encode_basestring_ascii(o)
            else:
                return encode_basestring(o)
        # This doesn't pass the iterator directly to ''.join() because the
        # exceptions aren't as detailed.  The list call should be roughly
        # equivalent to the PySequence_Fast that ''.join() would do.
>       chunks = self.iterencode(o, _one_shot=True)

.tox/c1/lib/python3.6/site-packages/simplejson/encoder.py:284: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <simplejson.encoder.JSONEncoder object at 0x7effe4a18860>
o = {'aggs': {'download_ranking': {'terms': {'field': 'file_key'}}}, 'query': {'bool': {'filter': [{'term': {'item_id': {...}}}, {'terms': {'root_file_id': [...]}}, {'range': {'timestamp': {...}}}]}}, 'size': 0}
_one_shot = True

    def iterencode(self, o, _one_shot=False):
        """Encode the given object and yield each string
        representation as available.
    
        For example::
    
            for chunk in JSONEncoder().iterencode(bigobject):
                mysocket.write(chunk)
    
        """
        if self.check_circular:
            markers = {}
        else:
            markers = None
        if self.ensure_ascii:
            _encoder = encode_basestring_ascii
        else:
            _encoder = encode_basestring
        if self.encoding != 'utf-8':
            def _encoder(o, _orig_encoder=_encoder, _encoding=self.encoding):
                if isinstance(o, binary_type):
                    o = o.decode(_encoding)
                return _orig_encoder(o)
    
        def floatstr(o, allow_nan=self.allow_nan, ignore_nan=self.ignore_nan,
                _repr=FLOAT_REPR, _inf=PosInf, _neginf=-PosInf):
            # Check for specials. Note that this type of test is processor
            # and/or platform-specific, so do tests which don't depend on
            # the internals.
    
            if o != o:
                text = 'NaN'
            elif o == _inf:
                text = 'Infinity'
            elif o == _neginf:
                text = '-Infinity'
            else:
                if type(o) != float:
                    # See #118, do not trust custom str/repr
                    o = float(o)
                return _repr(o)
    
            if ignore_nan:
                text = 'null'
            elif not allow_nan:
                raise ValueError(
                    "Out of range float values are not JSON compliant: " +
                    repr(o))
    
            return text
    
        key_memo = {}
        int_as_string_bitcount = (
            53 if self.bigint_as_string else self.int_as_string_bitcount)
        if (_one_shot and c_make_encoder is not None
                and self.indent is None):
            _iterencode = c_make_encoder(
                markers, self.default, _encoder, self.indent,
                self.key_separator, self.item_separator, self.sort_keys,
                self.skipkeys, self.allow_nan, key_memo, self.use_decimal,
                self.namedtuple_as_object, self.tuple_as_array,
                int_as_string_bitcount,
                self.item_sort_key, self.encoding, self.for_json,
                self.ignore_nan, decimal.Decimal, self.iterable_as_array)
        else:
            _iterencode = _make_iterencode(
                markers, self.default, _encoder, self.indent, floatstr,
                self.key_separator, self.item_separator, self.sort_keys,
                self.skipkeys, _one_shot, self.use_decimal,
                self.namedtuple_as_object, self.tuple_as_array,
                int_as_string_bitcount,
                self.item_sort_key, self.encoding, self.for_json,
                self.iterable_as_array, Decimal=decimal.Decimal)
        try:
>           return _iterencode(o, 0)

.tox/c1/lib/python3.6/site-packages/simplejson/encoder.py:366: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <elasticsearch.serializer.JSONSerializer object at 0x7f0011e618d0>
data = <function get_timezone at 0x7f0015f7e620>

    def default(self, data):
        if isinstance(data, (date, datetime)):
            return data.isoformat()
        elif isinstance(data, Decimal):
            return float(data)
        elif isinstance(data, uuid.UUID):
            return str(data)
>       raise TypeError("Unable to serialize %r (type: %s)" % (data, type(data)))
E       TypeError: Unable to serialize <function get_timezone at 0x7f0015f7e620> (type: <class 'function'>)

.tox/c1/lib/python3.6/site-packages/elasticsearch/serializer.py:34: TypeError

During handling of the above exception, another exception occurred:

app = <Flask 'testapp'>
esindex = <Elasticsearch([{'host': 'elasticsearch', 'port': 9200}])>

    def test_ESWekoFileRankingQuery(app, esindex):
        import json
        from invenio_stats.proxies import current_stats
        query_download_total_cfg = current_stats.queries['item-file-download-aggs']
        query_download_total = query_download_total_cfg.query_class(**query_download_total_cfg.query_config)
    
        index = app.config["INDEXER_DEFAULT_INDEX"]
        doc_type = "stats-file-download"
    
        def register(i):
            with open(f"tests/data/test_events/event_download{i:02}.json","r") as f:
                esindex.index(index=index, doc_type=doc_type, id=f"{i}", body=json.load(f), refresh="true")
    
        def delete(i):
            esindex.delete(index=index, doc_type=doc_type, id=f"{i}", refresh="true")
    
        # 19 Exist result
        item_id = 1
        register(item_id)
        params = {
            'item_id': str(item_id),
            'root_file_id_list': ['root_file_id_01'],
        }
        assert query_download_total.run(**params) == {'start_date': None, 'end_date': None, 'download_ranking': {'doc_count_error_upper_bound': 0, 'sum_other_doc_count': 0, 'buckets': [{'key': 'test_file_01.txt', 'doc_count': 1}]}}
        delete(item_id)
    
        # 20 Not exist result
        assert query_download_total.run(**params) == {'start_date': None, 'end_date': None, 'download_ranking': {'doc_count_error_upper_bound': 0, 'sum_other_doc_count': 0, 'buckets': []}}
    
        # 21 Set period
        for i in range(2,6):
            register(i)
        params = {
            'item_id': str(item_id),
            'root_file_id_list': ['root_file_id_02'],
            'start_date': '2024-01-01',
            'end_date': '2024-01-31T23:59:59',
        }
>       res = query_download_total.run(**params)

tests/test_queries.py:368: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
invenio_stats/queries.py:679: in run
    query_result = agg_query.execute().to_dict()
.tox/c1/lib/python3.6/site-packages/elasticsearch_dsl/search.py:706: in execute
    **self._params
.tox/c1/lib/python3.6/site-packages/elasticsearch/client/utils.py:76: in _wrapped
    return func(*args, params=params, **kwargs)
.tox/c1/lib/python3.6/site-packages/elasticsearch/client/__init__.py:636: in search
    doc_type, '_search'), params=params, body=body)
.tox/c1/lib/python3.6/site-packages/elasticsearch/transport.py:280: in perform_request
    body = self.serializer.dumps(body)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <elasticsearch.serializer.JSONSerializer object at 0x7f0011e618d0>
data = {'aggs': {'download_ranking': {'terms': {'field': 'file_key'}}}, 'query': {'bool': {'filter': [{'term': {'item_id': {...}}}, {'terms': {'root_file_id': [...]}}, {'range': {'timestamp': {...}}}]}}, 'size': 0}

    def dumps(self, data):
        # don't serialize strings
        if isinstance(data, string_types):
            return data
    
        try:
            return json.dumps(
                data,
                default=self.default,
                ensure_ascii=False,
                separators=(',', ':'),
            )
        except (ValueError, TypeError) as e:
>           raise SerializationError(data, e)
E           elasticsearch.exceptions.SerializationError: ({'query': {'bool': {'filter': [{'term': {'item_id': {'value': '1', 'boost': 1}}}, {'terms': {'root_file_id': ['root_file_id_02']}}, {'range': {'timestamp': {'gte': '2024-01-01T00:00:00', 'lte': '2024-01-31T23:59:59', 'time_zone': <function get_timezone at 0x7f0015f7e620>}}}]}}, 'aggs': {'download_ranking': {'terms': {'field': 'file_key'}}}, 'size': 0}, TypeError("Unable to serialize <function get_timezone at 0x7f0015f7e620> (type: <class 'function'>)",))

.tox/c1/lib/python3.6/site-packages/elasticsearch/serializer.py:55: SerializationError
_____________________________ test_process_events ______________________________

app = <Flask 'testapp'>
es = <Elasticsearch([{'host': 'elasticsearch', 'port': 9200}])>
event_queues = None

    def test_process_events(app, es, event_queues):
        """Test process event."""
        current_stats.publish('file-download',
                              [dict(timestamp='2017-01-01T00:00:00',
                                    visitor_id='testuser1',
                                    unique_id='2017-01-01T00:00:00-hash',
                                    data='val')])
>       process_events.delay(['file-download'])

tests/test_tasks.py:24: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
.tox/c1/lib/python3.6/site-packages/celery/app/task.py:425: in delay
    return self.apply_async(args, kwargs)
.tox/c1/lib/python3.6/site-packages/celery/app/task.py:563: in apply_async
    link=link, link_error=link_error, **options)
.tox/c1/lib/python3.6/site-packages/celery/app/task.py:775: in apply
    ret = tracer(task_id, args, kwargs, request)
.tox/c1/lib/python3.6/site-packages/celery/app/trace.py:429: in trace_task
    I, R, state, retval = on_error(task_request, exc, uuid)
.tox/c1/lib/python3.6/site-packages/celery/app/trace.py:412: in trace_task
    R = retval = fun(*args, **kwargs)
invenio_stats/tasks.py:27: in process_events
    results.append((e, processor.run()))
invenio_stats/processors.py:243: in run
    chunk_size=50
.tox/c1/lib/python3.6/site-packages/elasticsearch/helpers/__init__.py:257: in bulk
    for ok, item in streaming_bulk(client, actions, **kwargs):
.tox/c1/lib/python3.6/site-packages/elasticsearch/helpers/__init__.py:180: in streaming_bulk
    client.transport.serializer):
.tox/c1/lib/python3.6/site-packages/elasticsearch/helpers/__init__.py:58: in _chunk_actions
    for action, data in actions:
invenio_stats/processors.py:192: in actionsiter
    for msg in self.queue.consume():
../invenio-queues/invenio_queues/queue.py:107: in consume
    with self.create_consumer() as consumer:
/usr/local/lib/python3.6/contextlib.py:81: in __enter__
    return next(self.gen)
../invenio-queues/invenio_queues/queue.py:96: in create_consumer
    yield self.consumer(conn)
../invenio-queues/invenio_queues/queue.py:83: in consumer
    no_ack=self.no_ack,
.tox/c1/src/kombu/kombu/compat.py:119: in __init__
    super(Consumer, self).__init__(self.backend, queue, **kwargs)
.tox/c1/src/kombu/kombu/messaging.py:386: in __init__
    self.revive(self.channel)
.tox/c1/src/kombu/kombu/compat.py:123: in revive
    super(Consumer, self).revive(channel)
.tox/c1/src/kombu/kombu/messaging.py:408: in revive
    self.declare()
.tox/c1/src/kombu/kombu/messaging.py:421: in declare
    queue.declare()
.tox/c1/src/kombu/kombu/entity.py:611: in declare
    self._create_queue(nowait=nowait, channel=channel)
.tox/c1/src/kombu/kombu/entity.py:620: in _create_queue
    self.queue_declare(nowait=nowait, passive=False, channel=channel)
.tox/c1/src/kombu/kombu/entity.py:655: in queue_declare
    nowait=nowait,
.tox/c1/lib/python3.6/site-packages/amqp/channel.py:1149: in queue_declare
    spec.Queue.DeclareOk, returns_tuple=True,
.tox/c1/lib/python3.6/site-packages/amqp/abstract_channel.py:88: in wait
    self.connection.drain_events(timeout=timeout)
.tox/c1/lib/python3.6/site-packages/amqp/connection.py:508: in drain_events
    while not self.blocking_read(timeout):
.tox/c1/lib/python3.6/site-packages/amqp/connection.py:514: in blocking_read
    return self.on_inbound_frame(frame)
.tox/c1/lib/python3.6/site-packages/amqp/method_framing.py:55: in on_frame
    callback(channel, method_sig, buf, None)
.tox/c1/lib/python3.6/site-packages/amqp/connection.py:521: in on_inbound_method
    method_sig, payload, content,
.tox/c1/lib/python3.6/site-packages/amqp/abstract_channel.py:145: in dispatch_method
    listener(*args)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <kombu.transport.pyamqp.Channel object at 0x7effe45f7048>
reply_code = 406
reply_text = "PRECONDITION_FAILED - inequivalent arg 'x-queue-type' for queue 'stats-file-download' in vhost '/': received the value 'quorum' of type 'longstr' but current is none"
class_id = 50, method_id = 10

    def _on_close(self, reply_code, reply_text, class_id, method_id):
        """Request a channel close.
    
        This method indicates that the sender wants to close the
        channel. This may be due to internal conditions (e.g. a forced
        shut-down) or due to an error handling a specific method, i.e.
        an exception.  When a close is due to an exception, the sender
        provides the class and method id of the method which caused
        the exception.
    
        RULE:
    
            After sending this method any received method except
            Channel.Close-OK MUST be discarded.
    
        RULE:
    
            The peer sending this method MAY use a counter or timeout
            to detect failure of the other peer to respond correctly
            with Channel.Close-OK..
    
        PARAMETERS:
            reply_code: short
    
                The reply code. The AMQ reply codes are defined in AMQ
                RFC 011.
    
            reply_text: shortstr
    
                The localised reply text.  This text can be logged as an
                aid to resolving issues.
    
            class_id: short
    
                failing method class
    
                When the close is provoked by a method exception, this
                is the class of the method.
    
            method_id: short
    
                failing method ID
    
                When the close is provoked by a method exception, this
                is the ID of the method.
        """
        self.send_method(spec.Channel.CloseOk)
        if not self.connection.is_closing:
            self._do_revive()
            raise error_for_code(
>               reply_code, reply_text, (class_id, method_id), ChannelError,
            )
E           amqp.exceptions.PreconditionFailed: Queue.declare: (406) PRECONDITION_FAILED - inequivalent arg 'x-queue-type' for queue 'stats-file-download' in vhost '/': received the value 'quorum' of type 'longstr' but current is none

.tox/c1/lib/python3.6/site-packages/amqp/channel.py:280: PreconditionFailed
____________________________ test_get_aggregations _____________________________

app = <Flask 'testapp'>
es = <Elasticsearch([{'host': 'elasticsearch', 'port': 9200}])>

    def test_get_aggregations(app, es):
        res = get_aggregations('', {})
        assert res=={}
    
        res = get_aggregations('test-stats-search', {'aggs': {}})
>       assert res=={'_shards': {'failed': 0, 'skipped': 0, 'successful': 5, 'total': 5}, 'hits': {'hits': [], 'max_score': None, 'total': 0}, 'timed_out': False, 'took': 0}
E       AssertionError: assert {'_shards': {...se, 'took': 2} == {'_shards': {'...se, 'took': 0}
E         Common items:
E         {'_shards': {'failed': 0, 'skipped': 0, 'successful': 5, 'total': 5},
E          'hits': {'hits': [], 'max_score': None, 'total': 0},
E          'timed_out': False}
E         Differing items:
E         {'took': 2} != {'took': 0}
E         Full diff:
E         {'_shards': {'failed': 0, 'skipped': 0, 'successful': 5, 'total': 5},
E         'hits': {'hits': [], 'max_score': None, 'total': 0},
E         'timed_out': False,
E         -  'took': 2}
E         ?          ^
E         +  'took': 0}
E         ?          ^

tests/test_utils.py:107: AssertionError
_____________________ test_query_record_view_report_helper _____________________

app = <Flask 'testapp'>
es = <Elasticsearch([{'host': 'elasticsearch', 'port': 9200}])>
db = <SQLAlchemy engine=postgresql+psycopg2://invenio:***@postgresql:5432/wekotest>
records = [(<PersistentIdentifier recid:1 / rec:ce364509-0478-40da-b8a4-51fbe15186c3 (R)>, {'recid': '1', 'year': 2015, 'stars':...': '4', 'year': 4242, 'stars': 5, 'title': ['Unknown film'], 'item_title': 'Unknown film'}, {'title': 'Unknown film'})]

    def test_query_record_view_report_helper(app, es, db, records):
        _id1 = str(uuid.uuid4())
        _id2 = str(uuid.uuid4())
        # Calculation
        _res = {
            'buckets': [
                {
                    'record_id': _id1,
                    'record_name': 'test name1',
                    'record_index_names': 'test index1',
                    'count': 2,
                    'pid_value': 1,
                    'cur_user_id': 1
                },
                {
                    'record_id': _id2,
                    'record_name': 'test name2',
                    'record_index_names': 'test index1',
                    'count': 1,
                    'pid_value': 2,
                    'cur_user_id': 1
                }
            ]
        }
        _data_list = []
        # Calculation
        with pytest.raises(Exception) as e:
>           QueryRecordViewReportHelper.Calculation(_res, _data_list)
E           Failed: DID NOT RAISE <class 'Exception'>

tests/test_utils.py:556: Failed
______________________ test_query_item_reg_report_helper _______________________

app = <Flask 'testapp'>
db = <SQLAlchemy engine=postgresql+psycopg2://invenio:***@postgresql:5432/wekotest>
event_queues = None
es = <Elasticsearch([{'host': 'elasticsearch', 'port': 9200}])>

    def test_query_item_reg_report_helper(app, db, event_queues,es):
        # get
        from invenio_search import current_search_client
        res = QueryItemRegReportHelper.get(target_report='1', unit='Day', start_date='2022-09-01', end_date='2022-09-15')
>       assert res=={'num_page': 2, 'page': 1, 'data': [{'count': 0.0, 'start_date': '2022-09-01 00:00:00', 'end_date': '2022-09-01 23:59:59', 'is_restricted': False}, {'count': 0.0, 'start_date': '2022-09-02 00:00:00', 'end_date': '2022-09-02 23:59:59', 'is_restricted': False}, {'count': 0.0, 'start_date': '2022-09-03 00:00:00', 'end_date': '2022-09-03 23:59:59', 'is_restricted': False}, {'count': 0.0, 'start_date': '2022-09-04 00:00:00', 'end_date': '2022-09-04 23:59:59', 'is_restricted': False}, {'count': 0.0, 'start_date': '2022-09-05 00:00:00', 'end_date': '2022-09-05 23:59:59', 'is_restricted': False}, {'count': 0.0, 'start_date': '2022-09-06 00:00:00', 'end_date': '2022-09-06 23:59:59', 'is_restricted': False}, {'count': 0.0, 'start_date': '2022-09-07 00:00:00', 'end_date': '2022-09-07 23:59:59', 'is_restricted': False}, {'count': 0.0, 'start_date': '2022-09-08 00:00:00', 'end_date': '2022-09-08 23:59:59', 'is_restricted': False}, {'count': 0.0, 'start_date': '2022-09-09 00:00:00', 'end_date': '2022-09-09 23:59:59', 'is_restricted': False}, {'count': 0.0, 'start_date': '2022-09-10 00:00:00', 'end_date': '2022-09-10 23:59:59', 'is_restricted': False}]}
E       AssertionError: assert {'data': [], ... 2, 'page': 1} == {'data': [{'co... 2, 'page': 1}
E         Common items:
E         {'num_page': 2, 'page': 1}
E         Differing items:
E         {'data': []} != {'data': [{'count': 0.0, 'end_date': '2022-09-01 23:59:59', 'is_restricted': False, 'start_date': '2022-09-01 00:00:00..., {'count': 0.0, 'end_date': '2022-09-06 23:59:59', 'is_restricted': False, 'start_date': '2022-09-06 00:00:00'}, ...]}
E         Full diff:
E         - {'data': [], 'num_page': 2, 'page': 1}
E         + {'data': [{'count': 0.0,
E         +            'end_date': '2022-09-01 23:59:59',
E         +            'is_restricted': False,
E         +            'start_date': '2022-09-01 00:00:00'},
E         +           {'count': 0.0,
E         +            'end_date': '2022-09-02 23:59:59',
E         +            'is_restricted': False,
E         +            'start_date': '2022-09-02 00:00:00'},
E         +           {'count': 0.0,
E         +            'end_date': '2022-09-03 23:59:59',
E         +            'is_restricted': False,
E         +            'start_date': '2022-09-03 00:00:00'},
E         +           {'count': 0.0,
E         +            'end_date': '2022-09-04 23:59:59',
E         +            'is_restricted': False,
E         +            'start_date': '2022-09-04 00:00:00'},
E         +           {'count': 0.0,
E         +            'end_date': '2022-09-05 23:59:59',
E         +            'is_restricted': False,
E         +            'start_date': '2022-09-05 00:00:00'},
E         +           {'count': 0.0,
E         +            'end_date': '2022-09-06 23:59:59',
E         +            'is_restricted': False,
E         +            'start_date': '2022-09-06 00:00:00'},
E         +           {'count': 0.0,
E         +            'end_date': '2022-09-07 23:59:59',
E         +            'is_restricted': False,
E         +            'start_date': '2022-09-07 00:00:00'},
E         +           {'count': 0.0,
E         +            'end_date': '2022-09-08 23:59:59',
E         +            'is_restricted': False,
E         +            'start_date': '2022-09-08 00:00:00'},
E         +           {'count': 0.0,
E         +            'end_date': '2022-09-09 23:59:59',
E         +            'is_restricted': False,
E         +            'start_date': '2022-09-09 00:00:00'},
E         +           {'count': 0.0,
E         +            'end_date': '2022-09-10 23:59:59',
E         +            'is_restricted': False,
E         +            'start_date': '2022-09-10 00:00:00'}],
E         +  'num_page': 2,
E         +  'page': 1}

tests/test_utils.py:613: AssertionError
=============================== warnings summary ===============================
tests/test_aggregations.py::test_BookmarkAPI
  /code/modules/invenio-stats/.tox/c1/lib/python3.6/site-packages/jsonpath_ng/ext/string.py:18: DeprecationWarning: invalid escape sequence \(
    SUB = re.compile("sub\(/(.*)/,\s+(.*)\)")

tests/test_aggregations.py::test_BookmarkAPI
  /code/modules/invenio-stats/.tox/c1/lib/python3.6/site-packages/jsonpath_ng/ext/string.py:19: DeprecationWarning: invalid escape sequence \(
    SPLIT = re.compile("split\((.),\s+(\d+),\s+(\d+|-1)\)")

tests/test_aggregations.py::test_BookmarkAPI
  /code/modules/invenio-stats/.tox/c1/lib/python3.6/site-packages/jsonpath_ng/ext/string.py:20: DeprecationWarning: invalid escape sequence \(
    STR = re.compile("str\(\)")

tests/test_aggregations.py::test_BookmarkAPI
  /code/modules/invenio-stats/.tox/c1/bin/bagit.py:926: DeprecationWarning: invalid escape sequence \c
    """

tests/test_aggregations.py::test_BookmarkAPI
  /code/modules/invenio-stats/.tox/c1/lib/python3.6/site-packages/b2handle/clientcredentials.py:102: DeprecationWarning: invalid escape sequence \*
    '''

tests/test_aggregations.py::test_BookmarkAPI
  /code/modules/invenio-stats/.tox/c1/lib/python3.6/site-packages/b2handle/handleexceptions.py:128: DeprecationWarning: invalid escape sequence \s
    pat = re.compile('>[\s]+<')

tests/test_aggregations.py::test_BookmarkAPI
  /code/modules/invenio-stats/.tox/c1/lib/python3.6/site-packages/past/types/oldstr.py:33: DeprecationWarning: invalid escape sequence \d
    """

tests/test_aggregations.py::test_BookmarkAPI
  /code/modules/invenio-stats/.tox/c1/lib/python3.6/site-packages/b2handle/handleclient.py:177: DeprecationWarning: invalid escape sequence \*
    '''

tests/test_aggregations.py::test_BookmarkAPI
  /code/modules/invenio-stats/.tox/c1/lib/python3.6/site-packages/b2handle/handleclient.py:197: DeprecationWarning: invalid escape sequence \*
    '''

tests/test_aggregations.py::test_BookmarkAPI
  /code/modules/invenio-stats/.tox/c1/lib/python3.6/site-packages/b2handle/handleclient.py:230: DeprecationWarning: invalid escape sequence \*
    '''

tests/test_aggregations.py::test_BookmarkAPI
  /code/modules/invenio-stats/.tox/c1/lib/python3.6/site-packages/b2handle/handleclient.py:248: DeprecationWarning: invalid escape sequence \*
    '''

tests/test_aggregations.py::test_BookmarkAPI
  /code/modules/invenio-stats/.tox/c1/lib/python3.6/site-packages/citeproc/formatter/rst.py:8: DeprecationWarning: invalid escape sequence \*
    text = text.replace('*', '\*')

tests/test_aggregations.py::test_BookmarkAPI
  /code/modules/invenio-stats/.tox/c1/lib/python3.6/site-packages/citeproc/formatter/rst.py:9: DeprecationWarning: invalid escape sequence \`
    text = text.replace('`', '\`')

tests/test_aggregations.py::test_BookmarkAPI
  /code/modules/invenio-stats/.tox/c1/lib/python3.6/site-packages/citeproc/model.py:671: DeprecationWarning: invalid escape sequence \d
    m = re.search('\d+', first)

tests/test_aggregations.py::test_BookmarkAPI
  /code/modules/invenio-stats/.tox/c1/lib/python3.6/site-packages/citeproc/source/bibtex/bibtex.py:156: DeprecationWarning: invalid escape sequence \d
    RE_DAY = '(?P<day>\d+)'

tests/test_aggregations.py::test_BookmarkAPI
  /code/modules/invenio-stats/.tox/c1/lib/python3.6/site-packages/citeproc/source/bibtex/bibtex.py:157: DeprecationWarning: invalid escape sequence \w
    RE_MONTH = '(?P<month>\w+)'

tests/test_aggregations.py::test_BookmarkAPI
  /code/modules/invenio-stats/.tox/c1/lib/python3.6/site-packages/sickle/utils.py:20: DeprecationWarning: invalid escape sequence \{
    return re.search('(\{.*\})', element.tag).group(1)

tests/test_aggregations.py::test_BookmarkAPI
tests/test_aggregations.py::test_wrong_intervals
tests/test_aggregations.py::test_StatAggregator
tests/test_cli.py::test_events_process
tests/test_cli.py::test_events_delete_restore
tests/test_cli.py::test_aggregations_process[indexed_file_download_events0]
tests/test_cli.py::test_aggregations_delete[aggregated_file_download_events0]
tests/test_cli.py::test_aggregations_list_bookmarks[aggregated_file_download_events0]
tests/test_cli.py::test_aggregations_deleteindex_restore
tests/test_cli.py::test_partition_create
tests/test_event_builders.py::test_celery_task_event_builder
tests/test_event_builders.py::test_file_download_event_builder
tests/test_event_builders.py::test_build_celery_task_unique_id
tests/test_event_builders.py::test_copy_record_index_list
tests/test_event_builders.py::test_copy_user_group_list
tests/test_event_builders.py::test_copy_search_keyword
tests/test_event_builders.py::test_copy_search_type
tests/test_event_builders.py::test_record_view_event_builder
tests/test_event_builders.py::test_top_view_event_builder
tests/test_event_builders.py::test_build_top_unique_id
tests/test_event_builders.py::test_build_item_create_unique_id
tests/test_event_builders.py::test_resolve_address
tests/test_event_builders.py::test_search_event_builder
tests/test_event_builders.py::test_build_search_unique_id
tests/test_event_builders.py::test_build_search_detail_condition
tests/test_event_builders.py::test_item_create_event_builder
tests/test_models.py::test_StatsEvents
tests/test_models.py::test_StatsAggregation
tests/test_models.py::test_StatsBookmark
tests/test_models.py::test_get_stats_events_partition_tables
tests/test_models.py::test_make_stats_events_partition_table
tests/test_processors.py::test_anonymiation_salt
tests/test_processors.py::test_events_indexer_preprocessors
tests/test_processors.py::test_events_indexer_id_windowing
tests/test_processors.py::test_double_clicks
tests/test_queries.py::test_query
tests/test_queries.py::test_date_histogram_query
tests/test_queries.py::test_terms_query[mock_execute0-1-tests/data/ESTermsQuery_result01.json-aggregated_file_download_events0]
tests/test_queries.py::test_terms_query[mock_execute1-1-tests/data/ESTermsQuery_result02.json-aggregated_file_download_events0]
tests/test_queries.py::test_terms_query[mock_execute2-16-tests/data/ESTermsQuery_result03.json-aggregated_file_download_events0]
tests/test_queries.py::test_terms_query2
tests/test_queries.py::test_weko_file_stats_query
tests/test_queries.py::test_weko_terms_query
tests/test_queries.py::test_ESWekoFileRankingQuery
tests/test_tasks.py::test_process_events
tests/test_utils.py::test_get_anonymization_salt
tests/test_utils.py::test_get_user
tests/test_utils.py::test_obj_or_import_string
tests/test_utils.py::test_load_or_import_from_config
tests/test_utils.py::test_default_permission_factory
tests/test_utils.py::test_get_aggregations
tests/test_utils.py::test_get_start_end_date
tests/test_utils.py::test_agg_bucket_sort
tests/test_utils.py::test_parse_bucket_response
tests/test_utils.py::test_get_doctype
tests/test_utils.py::test_is_valid_access
tests/test_utils.py::test_query_file_reports_helper[aggregated_file_download_events0]
tests/test_utils.py::test_query_file_reports_helper_error
tests/test_utils.py::test_query_search_report_helper
tests/test_utils.py::test_query_search_report_helper_error
tests/test_utils.py::test_query_common_reports_helper
tests/test_utils.py::test_query_common_reports_helper_error
tests/test_utils.py::test_query_record_view_per_index_report_helper
tests/test_utils.py::test_query_record_view_per_index_report_helper_error
tests/test_utils.py::test_query_record_view_report_helper
tests/test_utils.py::test_query_record_view_report_helper_error
tests/test_utils.py::test_query_item_reg_report_helper
tests/test_utils.py::test_query_item_reg_report_helper_error
tests/test_utils.py::test_query_ranking_helper
tests/test_utils.py::test_query_ranking_helper_error
tests/test_utils.py::test_StatsCliUtil
tests/test_views.py::test_stats_query_resource_guest
tests/test_views.py::test_stats_query_resource_com
tests/test_views.py::test_stats_query_resource_admin
tests/test_views.py::test_stats_query_resource_error
tests/test_views.py::test_query_record_view_count
tests/test_views.py::test_query_record_view_count_error
tests/test_views.py::test_query_file_stats_count
tests/test_views.py::test_query_item_reg_report[0-403]
tests/test_views.py::test_query_item_reg_report[1-200]
tests/test_views.py::test_query_item_reg_report[2-200]
tests/test_views.py::test_query_item_reg_report[3-403]
tests/test_views.py::test_query_item_reg_report[4-403]
tests/test_views.py::test_query_record_view_report[0-403]
tests/test_views.py::test_query_record_view_report[1-200]
tests/test_views.py::test_query_record_view_report[2-200]
tests/test_views.py::test_query_record_view_report[3-403]
tests/test_views.py::test_query_record_view_report[4-403]
tests/test_views.py::test_query_record_view_per_index_report[0-403]
tests/test_views.py::test_query_record_view_per_index_report[1-200]
tests/test_views.py::test_query_record_view_per_index_report[2-200]
tests/test_views.py::test_query_record_view_per_index_report[3-403]
tests/test_views.py::test_query_record_view_per_index_report[4-403]
tests/test_views.py::test_query_file_reports[0-403]
tests/test_views.py::test_query_file_reports[1-200]
tests/test_views.py::test_query_file_reports[2-200]
tests/test_views.py::test_query_file_reports[3-403]
tests/test_views.py::test_query_file_reports[4-403]
tests/test_views.py::test_query_common_reports
tests/test_views.py::test_query_celery_task_report[0-403]
tests/test_views.py::test_query_celery_task_report[1-200]
tests/test_views.py::test_query_celery_task_report[2-200]
tests/test_views.py::test_query_celery_task_report[3-403]
tests/test_views.py::test_query_celery_task_report[4-403]
tests/test_views.py::test_query_search_report[0-403]
tests/test_views.py::test_query_search_report[1-200]
tests/test_views.py::test_query_search_report[2-200]
tests/test_views.py::test_query_search_report[3-403]
tests/test_views.py::test_query_search_report[4-403]
tests/test_views.py::test_dbsession_clean
  /code/modules/invenio-stats/.tox/c1/lib/python3.6/site-packages/flask_caching/__init__.py:241: DeprecationWarning: Using the initialization functions in flask_caching.backend is deprecated.  Use the a full path to backend classes directly.
    category=DeprecationWarning,

tests/test_models.py::test_StatsEvents
  /code/modules/invenio-stats/.tox/c1/lib/python3.6/site-packages/sqlalchemy/sql/crud.py:793: SAWarning: Column 'stats_events.id' is marked as a member of the primary key for table 'stats_events', but has no Python-side or server-side default generator indicated, nor does it indicate 'autoincrement=True' or 'nullable=True', and no explicit value is passed.  Primary key columns typically may not store NULL. Note that as of SQLAlchemy 1.1, 'autoincrement=True' must be indicated explicitly for composite (e.g. multicolumn) primary keys if AUTO_INCREMENT/SERIAL/IDENTITY behavior is expected for one of the columns in the primary key. CREATE TABLE statements are impacted by this change as well on most backends.
    util.warn(msg)

tests/test_processors.py::test_anonymiation_salt
  /code/modules/invenio-stats/.tox/c1/lib/python3.6/site-packages/sqlalchemy/ext/declarative/clsregistry.py:128: SAWarning: This declarative base already contains a class with the same class name and module name as sqlalchemy_continuum.model_builder.RecordMetadataVersion, and will be replaced in the string-lookup table.
    % (item.__module__, item.__name__)

tests/test_processors.py::test_anonymiation_salt
  /code/modules/invenio-stats/.tox/c1/lib/python3.6/site-packages/sqlalchemy/ext/declarative/clsregistry.py:128: SAWarning: This declarative base already contains a class with the same class name and module name as sqlalchemy_continuum.model_builder.ItemTypeVersion, and will be replaced in the string-lookup table.
    % (item.__module__, item.__name__)

tests/test_processors.py::test_anonymiation_salt
  /code/modules/invenio-stats/.tox/c1/lib/python3.6/site-packages/sqlalchemy/ext/declarative/clsregistry.py:128: SAWarning: This declarative base already contains a class with the same class name and module name as sqlalchemy_continuum.model_builder.ItemTypeMappingVersion, and will be replaced in the string-lookup table.
    % (item.__module__, item.__name__)

tests/test_processors.py::test_anonymiation_salt
  /code/modules/invenio-stats/.tox/c1/lib/python3.6/site-packages/sqlalchemy/ext/declarative/clsregistry.py:128: SAWarning: This declarative base already contains a class with the same class name and module name as sqlalchemy_continuum.model_builder.ItemMetadataVersion, and will be replaced in the string-lookup table.
    % (item.__module__, item.__name__)

tests/test_processors.py::test_anonymiation_salt
  /code/modules/invenio-stats/.tox/c1/lib/python3.6/site-packages/sqlalchemy/ext/declarative/clsregistry.py:128: SAWarning: This declarative base already contains a class with the same class name and module name as sqlalchemy_continuum.model_builder.FileMetadataVersion, and will be replaced in the string-lookup table.
    % (item.__module__, item.__name__)

tests/test_processors.py::test_anonymiation_salt
  /code/modules/invenio-stats/.tox/c1/lib/python3.6/site-packages/sqlalchemy/ext/declarative/clsregistry.py:128: SAWarning: This declarative base already contains a class with the same class name and module name as sqlalchemy_continuum.model_builder.OAIServerSchemaVersion, and will be replaced in the string-lookup table.
    % (item.__module__, item.__name__)

tests/test_processors.py::test_anonymiation_salt
  /code/modules/invenio-stats/.tox/c1/lib/python3.6/site-packages/sqlalchemy/orm/properties.py:212: SAWarning: On mapper Mapper|RecordMetadataVersion|records_metadata_version, primary key column 'records_metadata_version.transaction_id' is being combined with distinct primary key column 'records_metadata_version.transaction_id' in attribute 'transaction_id'. Use explicit properties to give each column its own mapped attribute name.
    % (self.parent, self.columns[1], self.columns[0], self.key)

tests/test_processors.py::test_anonymiation_salt
  /code/modules/invenio-stats/.tox/c1/lib/python3.6/site-packages/sqlalchemy/orm/properties.py:212: SAWarning: On mapper Mapper|ItemTypeVersion|item_type_version, primary key column 'item_type_version.transaction_id' is being combined with distinct primary key column 'item_type_version.transaction_id' in attribute 'transaction_id'. Use explicit properties to give each column its own mapped attribute name.
    % (self.parent, self.columns[1], self.columns[0], self.key)

tests/test_processors.py::test_anonymiation_salt
  /code/modules/invenio-stats/.tox/c1/lib/python3.6/site-packages/sqlalchemy/orm/properties.py:212: SAWarning: On mapper Mapper|ItemTypeMappingVersion|item_type_mapping_version, primary key column 'item_type_mapping_version.transaction_id' is being combined with distinct primary key column 'item_type_mapping_version.transaction_id' in attribute 'transaction_id'. Use explicit properties to give each column its own mapped attribute name.
    % (self.parent, self.columns[1], self.columns[0], self.key)

tests/test_processors.py::test_anonymiation_salt
  /code/modules/invenio-stats/.tox/c1/lib/python3.6/site-packages/sqlalchemy/orm/properties.py:212: SAWarning: On mapper Mapper|ItemMetadataVersion|item_metadata_version, primary key column 'item_metadata_version.transaction_id' is being combined with distinct primary key column 'item_metadata_version.transaction_id' in attribute 'transaction_id'. Use explicit properties to give each column its own mapped attribute name.
    % (self.parent, self.columns[1], self.columns[0], self.key)

tests/test_processors.py::test_anonymiation_salt
  /code/modules/invenio-stats/.tox/c1/lib/python3.6/site-packages/sqlalchemy/orm/properties.py:212: SAWarning: On mapper Mapper|FileMetadataVersion|file_metadata_version, primary key column 'file_metadata_version.transaction_id' is being combined with distinct primary key column 'file_metadata_version.transaction_id' in attribute 'transaction_id'. Use explicit properties to give each column its own mapped attribute name.
    % (self.parent, self.columns[1], self.columns[0], self.key)

tests/test_processors.py::test_anonymiation_salt
  /code/modules/invenio-stats/.tox/c1/lib/python3.6/site-packages/sqlalchemy/orm/properties.py:212: SAWarning: On mapper Mapper|OAIServerSchemaVersion|oaiserver_schema_version, primary key column 'oaiserver_schema_version.transaction_id' is being combined with distinct primary key column 'oaiserver_schema_version.transaction_id' in attribute 'transaction_id'. Use explicit properties to give each column its own mapped attribute name.
    % (self.parent, self.columns[1], self.columns[0], self.key)

tests/test_views.py::test_stats_query_resource_com
tests/test_views.py::test_stats_query_resource_admin
tests/test_views.py::test_stats_query_resource_error
tests/test_views.py::test_query_item_reg_report[0-403]
tests/test_views.py::test_query_item_reg_report[1-200]
tests/test_views.py::test_query_item_reg_report[2-200]
tests/test_views.py::test_query_item_reg_report[3-403]
tests/test_views.py::test_query_item_reg_report[4-403]
tests/test_views.py::test_query_record_view_report[0-403]
tests/test_views.py::test_query_record_view_report[1-200]
tests/test_views.py::test_query_record_view_report[2-200]
tests/test_views.py::test_query_record_view_report[3-403]
tests/test_views.py::test_query_record_view_report[4-403]
tests/test_views.py::test_query_record_view_per_index_report[0-403]
tests/test_views.py::test_query_record_view_per_index_report[1-200]
tests/test_views.py::test_query_record_view_per_index_report[2-200]
tests/test_views.py::test_query_record_view_per_index_report[3-403]
tests/test_views.py::test_query_record_view_per_index_report[4-403]
tests/test_views.py::test_query_file_reports[0-403]
tests/test_views.py::test_query_file_reports[1-200]
tests/test_views.py::test_query_file_reports[2-200]
tests/test_views.py::test_query_file_reports[3-403]
tests/test_views.py::test_query_file_reports[4-403]
tests/test_views.py::test_query_celery_task_report[0-403]
tests/test_views.py::test_query_celery_task_report[1-200]
tests/test_views.py::test_query_celery_task_report[2-200]
tests/test_views.py::test_query_celery_task_report[3-403]
tests/test_views.py::test_query_celery_task_report[4-403]
tests/test_views.py::test_query_search_report[0-403]
tests/test_views.py::test_query_search_report[1-200]
tests/test_views.py::test_query_search_report[2-200]
tests/test_views.py::test_query_search_report[3-403]
tests/test_views.py::test_query_search_report[4-403]
  /code/modules/invenio-stats/.tox/c1/lib/python3.6/site-packages/flask/sessions.py:211: UserWarning: "localhost" is not a valid cookie domain, it must contain a ".". Add an entry to your hosts file, for example "localhost.localdomain", and use that instead.
    ' "{rv}.localdomain", and use that instead.'.format(rv=rv)

-- Docs: https://docs.pytest.org/en/latest/warnings.html

---------- coverage: platform linux, python 3.6.15-final-0 -----------
Name                                                                Stmts   Miss Branch BrPart  Cover
-----------------------------------------------------------------------------------------------------
invenio_stats/__init__.py                                               6      0      0      0   100%
invenio_stats/aggregations.py                                         186     91     73      8    43%
invenio_stats/cli.py                                                  173     34     34      7    74%
invenio_stats/config.py                                                26      0      0      0   100%
invenio_stats/contrib/__init__.py                                       1      0      0      0   100%
invenio_stats/contrib/aggregations/__init__.py                          1      0      0      0   100%
invenio_stats/contrib/aggregations/aggr_celery_task/__init__.py         1      0      0      0   100%
invenio_stats/contrib/aggregations/aggr_file_download/__init__.py       1      0      0      0   100%
invenio_stats/contrib/aggregations/aggr_file_preview/__init__.py        1      0      0      0   100%
invenio_stats/contrib/aggregations/aggr_item_create/__init__.py         1      0      0      0   100%
invenio_stats/contrib/aggregations/aggr_record_view/__init__.py         1      0      0      0   100%
invenio_stats/contrib/aggregations/aggr_search/__init__.py              1      0      0      0   100%
invenio_stats/contrib/aggregations/aggr_top_view/__init__.py            1      0      0      0   100%
invenio_stats/contrib/celery_task/__init__.py                           1      1      0      0     0%
invenio_stats/contrib/event_builders.py                               124      2     42     10    93%
invenio_stats/contrib/file_download/__init__.py                         1      0      0      0   100%
invenio_stats/contrib/file_preview/__init__.py                          1      1      0      0     0%
invenio_stats/contrib/item_create/__init__.py                           1      1      0      0     0%
invenio_stats/contrib/record_view/__init__.py                           1      0      0      0   100%
invenio_stats/contrib/registrations.py                                 15      1      0      0    93%
invenio_stats/contrib/search/__init__.py                                1      1      0      0     0%
invenio_stats/contrib/top_view/__init__.py                              1      1      0      0     0%
invenio_stats/errors.py                                                20      0     16      0   100%
invenio_stats/ext.py                                                  110     19     56      8    80%
invenio_stats/models.py                                               112      0     22      2    99%
invenio_stats/permissions.py                                            4      0      0      0   100%
invenio_stats/processors.py                                            95     13     32      5    84%
invenio_stats/proxies.py                                                5      0      2      0   100%
invenio_stats/queries.py                                              359     54    191     21    80%
invenio_stats/queues.py                                                 4      0      2      0   100%
invenio_stats/receivers.py                                             29     10     16      0    64%
invenio_stats/tasks.py                                                 25     12      4      1    48%
invenio_stats/templates.py                                              6      0      4      0   100%
invenio_stats/utils.py                                                930    193    406     37    75%
invenio_stats/version.py                                                3      0      0      0   100%
invenio_stats/views.py                                                328     19     98      1    93%
-----------------------------------------------------------------------------------------------------
TOTAL                                                                2576    453    998    100    78%
Coverage HTML written to dir htmlcov
Coverage XML written to file coverage.xml

== 11 failed, 107 passed, 5 skipped, 173 warnings, 7 error in 429.82 seconds ===
ERROR: InvocationError for command /code/modules/invenio-stats/.tox/c1/bin/pytest --cov=invenio_stats tests -v -vv --cov-branch --cov-report=term --cov-report=xml --cov-report=html --cov-config=tox.ini --basetemp=/code/modules/invenio-stats/.tox/c1/tmp (exited with code 1)
___________________________________ summary ____________________________________
ERROR:   c1: commands failed
